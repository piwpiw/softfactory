# Logstash Configuration for SoftFactory
# Version: 1.0
# Updated: 2026-02-25
#
# Processes JSON logs from logs/app.log and ships to Elasticsearch
# Creates daily indices: softfactory-logs-YYYY.MM.dd

input {
  # Read JSON logs from file
  file {
    path => "/logs/app.log"
    start_position => "beginning"
    sincedb_path => "/var/lib/logstash/.sincedb_softfactory"
    codec => json {
      charset => "UTF-8"
    }
    # Tag for easy filtering
    tags => ["softfactory", "application"]
  }

  # Optional: Read from syslog if Flask logs there
  # syslog {
  #   port => 514
  #   tags => ["softfactory", "syslog"]
  # }
}

filter {
  # Only process our logs
  if "softfactory" in [tags] {

    # Parse timestamp to @timestamp field
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601" ]
        target => "@timestamp"
      }
    }

    # Add metadata
    mutate {
      add_field => {
        "environment" => "production"
        "service" => "softfactory-api"
        "region" => "us-east-1"
      }
    }

    # Extract request details for better filtering
    if [request_id] {
      mutate {
        add_field => { "[@metadata][correlation_id]" => "%{request_id}" }
      }
    }

    # If user_id is present, enrich with user context
    if [user_id] {
      mutate {
        convert => { "user_id" => "integer" }
      }
    }

    # Convert numeric fields to proper types
    mutate {
      convert => {
        "status" => "integer"
        "content_length" => "integer"
        "latency_ms" => "float"
        "line_number" => "integer"
      }
    }

    # Add severity level for easier filtering
    if [status] >= 500 {
      mutate {
        add_field => { "severity" => "ERROR" }
      }
    } else if [status] >= 400 {
      mutate {
        add_field => { "severity" => "WARNING" }
      }
    } else {
      mutate {
        add_field => { "severity" => "INFO" }
      }
    }

    # Grok patterns for non-JSON fallback (if any plain text logs slip through)
    if "_jsonparsefailure" in [tags] {
      grok {
        match => {
          "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} %{GREEDYDATA:message}"
        }
        add_tag => ["fallback_parsed"]
        remove_tag => ["_jsonparsefailure"]
      }
    }

    # Detect error patterns for alerting
    if [message] =~ /(?i)(error|exception|failed)/ {
      mutate {
        add_field => { "error_flag" => true }
      }
    }

    # GeoIP enrichment for request source (optional)
    # if [remote_addr] {
    #   geoip {
    #     source => "remote_addr"
    #     target => "geoip"
    #   }
    # }

    # Remove unwanted fields to reduce storage
    mutate {
      remove_field => [
        "[@metadata][beat]",
        "[@metadata][type]",
        "host",
        "ecs"
      ]
    }

  }
}

output {
  # Primary: Send to Elasticsearch with date-based index
  if "softfactory" in [tags] {
    elasticsearch {
      hosts => ["${ES_HOST:elasticsearch}:9200"]
      # Daily indices for easier management
      index => "softfactory-logs-%{+YYYY.MM.dd}"
      codec => json
      # Buffer settings for performance
      flush_interval => 1
      retry_on_conflict => 3
    }
  }

  # Secondary: Send errors to separate index for quick access
  if [severity] == "ERROR" {
    elasticsearch {
      hosts => ["${ES_HOST:elasticsearch}:9200"]
      index => "softfactory-errors-%{+YYYY.MM.dd}"
      codec => json
    }
  }

  # Debug: Output to stdout (for troubleshooting)
  # Disable in production to improve performance
  # stdout {
  #   codec => rubydebug
  # }
}
