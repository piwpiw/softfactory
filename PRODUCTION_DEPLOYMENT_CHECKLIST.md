# ğŸš¢ Production Deployment Checklist â€” SoftFactory v2.0

> **Purpose**: ```
> **Status**: ğŸŸ¢ ACTIVE (ê´€ë¦¬ ì¤‘)
> **Impact**: [Engineering / Operations]

---

## âš¡ Executive Summary (í•µì‹¬ ìš”ì•½)
- **ì£¼ìš” ë‚´ìš©**: ë³¸ ë¬¸ì„œëŠ” Production Deployment Checklist â€” SoftFactory v2.0 ê´€ë ¨ í•µì‹¬ ëª…ì„¸ ë° ê´€ë¦¬ í¬ì¸íŠ¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
- **ìƒíƒœ**: í˜„ì¬ ìµœì‹ í™” ì™„ë£Œ ë° ê²€í†  ë¨.
- **ì—°ê´€ ë¬¸ì„œ**: [Master Index](./NOTION_MASTER_INDEX.md)

---

> **Complete step-by-step checklist for deploying all 8 agent teams' work to production**
>
> **Date:** 2026-02-26 | **Estimated Duration:** 130 minutes | **Status:** READY FOR DEPLOYMENT

---

## PRE-DEPLOYMENT (15 minutes)

### 1. Infrastructure Readiness

```
â˜ PostgreSQL 14+ instance running
  â””â”€ Verify: psql -U postgres -c "SELECT version();"
  â””â”€ Create database: createdb softfactory
  â””â”€ Create application user: CREATE USER softfactory_app WITH PASSWORD 'xxx';

â˜ Redis 7+ instance running
  â””â”€ Verify: redis-cli ping â†’ PONG
  â””â”€ Set password in redis.conf
  â””â”€ Test auth: redis-cli -a <password> ping

â˜ Elasticsearch 8+ cluster running
  â””â”€ Verify: curl -X GET http://localhost:9200/
  â””â”€ Create index: curl -X PUT http://localhost:9200/softfactory_posts
  â””â”€ Install Nori analyzer plugin

â˜ Docker & Docker Compose installed
  â””â”€ Verify: docker --version && docker-compose --version
  â””â”€ Ensure Docker daemon is running

â˜ Domain & SSL certificate obtained
  â””â”€ DNS configured to point to server IP
  â””â”€ SSL certificate placed in /etc/ssl/certs/
  â””â”€ Test: curl -I https://yourdomain.com â†’ HTTP 200

â˜ Firewall rules configured
  â””â”€ Allow inbound: 80 (HTTP), 443 (HTTPS), 8000 (API), 5678 (n8n), 9200 (Elasticsearch)
  â””â”€ Restrict to known IPs where possible
```

### 2. External Service Credentials

```
â˜ AWS Account with S3 bucket created
  â””â”€ Bucket: softfactory-uploads
  â””â”€ Region: us-east-1
  â””â”€ Versioning: Enabled
  â””â”€ Server-side encryption: KMS (optional but recommended)
  â””â”€ IAM user created with S3-only permissions
  â””â”€ Access key & secret key saved in .env

â˜ CloudFront distribution created
  â””â”€ Origin: S3 bucket
  â””â”€ Domain: d*.cloudfront.net
  â””â”€ CNAME added to custom domain (optional)
  â””â”€ Cache policy: 30 days
  â””â”€ Domain saved as CLOUDFRONT_DOMAIN in .env

â˜ Stripe account (Live mode, not test)
  â””â”€ API keys: sk_live_* and pk_live_*
  â””â”€ Webhook endpoint created at: https://yourdomain.com/api/payment/webhook
  â””â”€ Webhook secret saved in .env (STRIPE_WEBHOOK_SECRET)
  â””â”€ Subscription products configured in Stripe dashboard
  â””â”€ KRW currency enabled in account settings

â˜ OAuth credentials obtained
  â”œâ”€ Google OAuth
  â”‚  â”œâ”€ Credentials at https://console.cloud.google.com/
  â”‚  â”œâ”€ OAuth consent screen configured
  â”‚  â”œâ”€ Authorized redirect URI: https://yourdomain.com/api/auth/oauth/google/callback
  â”‚  â”œâ”€ Client ID & secret saved in .env (GOOGLE_CLIENT_ID, GOOGLE_CLIENT_SECRET)
  â”‚
  â”œâ”€ Facebook OAuth
  â”‚  â”œâ”€ Credentials at https://developers.facebook.com/
  â”‚  â”œâ”€ App domain: yourdomain.com
  â”‚  â”œâ”€ Authorized redirect URI: https://yourdomain.com/api/auth/oauth/facebook/callback
  â”‚  â”œâ”€ App ID & secret saved in .env
  â”‚
  â””â”€ KakaoTalk OAuth
     â”œâ”€ Credentials at https://developers.kakao.com/
     â”œâ”€ OAuth redirect URI: https://yourdomain.com/api/auth/oauth/kakao/callback
     â”œâ”€ REST API key saved in .env (KAKAO_REST_API_KEY)

â˜ Firebase Cloud Messaging
  â”œâ”€ Project created in Firebase Console
  â”œâ”€ Service account JSON downloaded
  â”œâ”€ JSON file contents saved in .env (FIREBASE_PRIVATE_KEY, etc.)
  â”œâ”€ APNs certificate uploaded (for iOS push)

â˜ Email Service (SendGrid)
  â”œâ”€ Account created at sendgrid.com
  â”œâ”€ API key generated (SG.xxx...)
  â”œâ”€ Sender address verified (noreply@yourdomain.com)
  â”œâ”€ Email templates created (welcome, receipt, notifications, reset password)
  â”œâ”€ API key saved in .env (MAIL_PASSWORD)

â˜ Sentry (Error Tracking)
  â”œâ”€ Project created at sentry.io
  â”œâ”€ DSN obtained (https://xxx@sentry.io/xxx)
  â”œâ”€ Environment: production
  â”œâ”€ Alerts configured for critical errors
  â”œâ”€ DSN saved in .env (SENTRY_DSN)
```

### 3. Code & Environment Setup

```
â˜ Clone production branch
  â””â”€ git clone -b main https://github.com/yourorg/softfactory.git
  â””â”€ cd softfactory

â˜ Create .env file from template
  â””â”€ cp .env.example .env
  â””â”€ Fill all required variables (see section below)
  â””â”€ Verify no hardcoded secrets in code: grep -r "sk_" backend/ web/

â˜ Verify no debug mode enabled
  â””â”€ FLASK_ENV=production (not development)
  â””â”€ DEBUG=False
  â””â”€ SECRET_KEY=<random string min 32 chars>

â˜ Install dependencies
  â””â”€ pip install -r requirements.txt
  â””â”€ npm install (if using frontend build)

â˜ Build Docker image
  â””â”€ docker build -t softfactory:latest .
  â””â”€ Verify: docker images | grep softfactory
```

---

## ENVIRONMENT VARIABLES CHECKLIST (.env)

### REQUIRED VARIABLES

```
# Core Flask
FLASK_ENV=production
DEBUG=False
SECRET_KEY=<generate: python -c "import secrets; print(secrets.token_hex(32))">
SQLALCHEMY_DATABASE_URI=postgresql://softfactory_app:password@postgres-host:5432/softfactory
SQLALCHEMY_ECHO=False
SQLALCHEMY_POOL_SIZE=20
SQLALCHEMY_POOL_RECYCLE=3600

# JWT
JWT_SECRET_KEY=<generate: python -c "import secrets; print(secrets.token_hex(32))">
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRES=3600
JWT_REFRESH_TOKEN_EXPIRES=2592000

# Redis
REDIS_URL=redis://:password@redis-host:6379/0
REDIS_CACHE_TTL=3600
REDIS_SESSION_TTL=86400

# Database
DATABASE_URL=postgresql://...  (duplicate of SQLALCHEMY_DATABASE_URI)

# AWS S3
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_S3_BUCKET=softfactory-uploads
AWS_S3_REGION=us-east-1
CLOUDFRONT_DOMAIN=d*.cloudfront.net

# Stripe
STRIPE_PUBLIC_KEY=pk_live_...
STRIPE_SECRET_KEY=sk_live_...
STRIPE_WEBHOOK_SECRET=whsec_...

# OAuth Credentials
GOOGLE_CLIENT_ID=xxx.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=...
FACEBOOK_APP_ID=...
FACEBOOK_APP_SECRET=...
KAKAO_REST_API_KEY=...

# Firebase
FIREBASE_PROJECT_ID=...
FIREBASE_PRIVATE_KEY_ID=...
FIREBASE_PRIVATE_KEY=-----BEGIN PRIVATE KEY-----...
FIREBASE_CLIENT_EMAIL=...
FIREBASE_CLIENT_ID=...

# Elasticsearch
ELASTICSEARCH_HOST=elasticsearch-host
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_PROTOCOL=https  (or http if internal)
ELASTICSEARCH_USERNAME=elastic
ELASTICSEARCH_PASSWORD=...

# Email
MAIL_SERVER=smtp.sendgrid.net
MAIL_PORT=587
MAIL_USERNAME=apikey
MAIL_PASSWORD=SG.xxx...
DEFAULT_MAIL_SENDER=noreply@yourdomain.com

# Application
ENVIRONMENT=production
HOSTNAME=yourdomain.com
PORT=8000
WORKERS=4  (for Gunicorn)
CORS_ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com
LOG_LEVEL=WARNING  (or INFO for initial debugging)

# Features
ENABLE_OAUTH_MOCK_MODE=False
ENABLE_2FA=True
ENABLE_PWA=True
ENABLE_WEBSOCKET=True
ENABLE_ELASTICSEARCH=True

# Monitoring
SENTRY_DSN=https://xxx@sentry.io/xxx
SENTRY_ENVIRONMENT=production
SENTRY_TRACES_SAMPLE_RATE=0.1

# n8n
N8N_HOST=n8n.yourdomain.com
N8N_PROTOCOL=https
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=<strong password>
WEBHOOK_TUNNEL_URL=https://n8n.yourdomain.com/
```

---

## PHASE 1: DATABASE SETUP (10 minutes)

```
â˜ Create PostgreSQL database
  â””â”€ createdb softfactory

â˜ Create database user with limited permissions
  â””â”€ psql -U postgres -c "CREATE USER softfactory_app WITH PASSWORD 'xxx';"
  â””â”€ psql -U postgres -c "GRANT CONNECT ON DATABASE softfactory TO softfactory_app;"
  â””â”€ psql -U postgres -c "GRANT USAGE ON SCHEMA public TO softfactory_app;"
  â””â”€ psql -U postgres -c "GRANT CREATE ON SCHEMA public TO softfactory_app;"

â˜ Run database migrations
  â””â”€ flask db init (if first time)
  â””â”€ flask db migrate -m "Initial migration"
  â””â”€ flask db upgrade
  â””â”€ Verify: psql -U softfactory_app -d softfactory -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public';"
  â””â”€ Expected: 40+ tables

â˜ Seed initial data
  â””â”€ python backend/scripts/seed_database.py
  â””â”€ Verify: SELECT COUNT(*) FROM users; (should be > 0)
  â””â”€ Verify: SELECT COUNT(*) FROM subscription_plans; (should be 3-4)

â˜ Create database backups
  â””â”€ pg_dump softfactory > /backups/softfactory_2026-02-26.sql
  â””â”€ Store backup in secure location (S3, separate server, etc.)

â˜ Configure automated backups
  â””â”€ Set up cron job: 0 2 * * * pg_dump softfactory | gzip > /backups/softfactory_$(date +\%Y-\%m-\%d).sql.gz
```

---

## PHASE 2: REDIS SETUP (5 minutes)

```
â˜ Start Redis service
  â””â”€ systemctl start redis-server (Linux)
  â””â”€ brew services start redis (macOS)
  â””â”€ docker run -d -p 6379:6379 redis:7 (Docker)

â˜ Test Redis connection
  â””â”€ redis-cli ping â†’ PONG
  â””â”€ redis-cli SET test_key "hello" â†’ OK
  â””â”€ redis-cli GET test_key â†’ "hello"
  â””â”€ redis-cli -a <password> ping (if password set)

â˜ Configure Redis persistence (optional but recommended)
  â””â”€ Edit /etc/redis/redis.conf:
     save 900 1     (save every 15 min if 1+ keys changed)
     save 300 10    (save every 5 min if 10+ keys changed)
     appendonly yes (AOF persistence)

â˜ Set Redis password
  â””â”€ Edit redis.conf: requirepass <strong_password>
  â””â”€ Update .env: REDIS_URL=redis://:password@host:6379/0
  â””â”€ Test: redis-cli -a <password> ping
```

---

## PHASE 3: ELASTICSEARCH SETUP (15 minutes)

```
â˜ Start Elasticsearch service
  â””â”€ Docker: docker run -d -p 9200:9200 -e discovery.type=single-node docker.elastic.co/elasticsearch/elasticsearch:8.0.0
  â””â”€ Systemd: systemctl start elasticsearch
  â””â”€ Verify: curl -X GET http://localhost:9200/

â˜ Create indices
  â””â”€ curl -X PUT http://localhost:9200/softfactory_posts -d '{
       "settings": {
         "number_of_shards": 1,
         "number_of_replicas": 0,
         "analysis": {
           "analyzer": {
             "nori_analyzer": {
               "type": "custom",
               "tokenizer": "nori_tokenizer"
             }
           }
         }
       },
       "mappings": {
         "properties": {
           "title": { "type": "text", "analyzer": "nori_analyzer" },
           "content": { "type": "text", "analyzer": "nori_analyzer" },
           "created_at": { "type": "date" }
         }
       }
     }'

â˜ Install Nori analyzer (Korean support)
  â””â”€ elasticsearch-plugin install analysis-nori
  â””â”€ Restart Elasticsearch

â˜ Index initial data
  â””â”€ python backend/scripts/index_elasticsearch.py
  â””â”€ Verify: curl -X GET http://localhost:9200/_cat/indices
  â””â”€ Expected: softfactory_posts, softfactory_reviews, softfactory_users

â˜ Test search functionality
  â””â”€ curl -X POST http://localhost:9200/softfactory_posts/_search -d '{"query": {"match_all": {}}}'
  â””â”€ Expected: Non-zero hits
```

---

## PHASE 4: FLASK API DEPLOYMENT (10 minutes)

```
â˜ Create Gunicorn service file
  â””â”€ cat > /etc/systemd/system/softfactory.service << 'EOF'
     [Unit]
     Description=SoftFactory API
     After=network.target postgresql.service redis.service

     [Service]
     Type=notify
     User=softfactory
     Group=softfactory
     WorkingDirectory=/opt/softfactory
     Environment="PATH=/opt/softfactory/venv/bin"
     Environment="PYTHONUNBUFFERED=1"
     EnvironmentFile=/opt/softfactory/.env
     ExecStart=/opt/softfactory/venv/bin/gunicorn \
       --workers 4 \
       --worker-class sync \
       --bind 127.0.0.1:8000 \
       --timeout 60 \
       --access-logfile /var/log/softfactory/access.log \
       --error-logfile /var/log/softfactory/error.log \
       backend.app:app

     Restart=always
     RestartSec=10

     [Install]
     WantedBy=multi-user.target
     EOF

â˜ Create application user
  â””â”€ useradd -m -s /bin/bash softfactory
  â””â”€ chown -R softfactory:softfactory /opt/softfactory
  â””â”€ chmod 700 /opt/softfactory/.env

â˜ Create log directory
  â””â”€ mkdir -p /var/log/softfactory
  â””â”€ chown softfactory:softfactory /var/log/softfactory
  â””â”€ chmod 755 /var/log/softfactory

â˜ Start Flask service
  â””â”€ systemctl daemon-reload
  â””â”€ systemctl start softfactory
  â””â”€ systemctl enable softfactory
  â””â”€ Verify: systemctl status softfactory

â˜ Test API health
  â””â”€ curl http://localhost:8000/api/health
  â””â”€ Expected: HTTP 200 + {"status": "ok"}
```

---

## PHASE 5: NGINX REVERSE PROXY (10 minutes)

```
â˜ Install Nginx
  â””â”€ apt-get install nginx (Ubuntu)
  â””â”€ brew install nginx (macOS)

â˜ Create Nginx config
  â””â”€ cat > /etc/nginx/sites-available/softfactory << 'EOF'
     upstream flask_app {
         server 127.0.0.1:8000;
     }

     server {
         listen 80;
         server_name yourdomain.com www.yourdomain.com;
         return 301 https://$server_name$request_uri;
     }

     server {
         listen 443 ssl http2;
         server_name yourdomain.com www.yourdomain.com;

         ssl_certificate /etc/ssl/certs/yourdomain.com.crt;
         ssl_certificate_key /etc/ssl/private/yourdomain.com.key;
         ssl_protocols TLSv1.2 TLSv1.3;
         ssl_ciphers HIGH:!aNULL:!MD5;
         ssl_prefer_server_ciphers on;

         # Security headers
         add_header X-Frame-Options "SAMEORIGIN";
         add_header X-Content-Type-Options "nosniff";
         add_header X-XSS-Protection "1; mode=block";
         add_header Referrer-Policy "strict-origin-when-cross-origin";

         client_max_body_size 50M;

         location / {
             proxy_pass http://flask_app;
             proxy_set_header Host $host;
             proxy_set_header X-Real-IP $remote_addr;
             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
             proxy_set_header X-Forwarded-Proto $scheme;
             proxy_redirect off;
         }

         location /static/ {
             alias /opt/softfactory/web/;
             expires 30d;
             add_header Cache-Control "public, immutable";
         }
     }
     EOF

â˜ Enable Nginx config
  â””â”€ ln -s /etc/nginx/sites-available/softfactory /etc/nginx/sites-enabled/
  â””â”€ nginx -t  (test config)
  â””â”€ systemctl restart nginx

â˜ Test HTTPS
  â””â”€ curl -I https://yourdomain.com
  â””â”€ Expected: HTTP 200
```

---

## PHASE 6: OAUTH & EXTERNAL SERVICES (10 minutes)

```
â˜ Test Google OAuth
  â””â”€ curl "http://localhost:8000/api/auth/oauth/google/url"
  â””â”€ Expected: auth_url, state_token
  â””â”€ Visit URL, authorize, capture authorization code
  â””â”€ Call callback with code
  â””â”€ Expected: access_token, refresh_token

â˜ Test Stripe Integration
  â””â”€ curl "http://localhost:8000/api/payment/plans"
  â””â”€ Expected: 200 OK + list of plans
  â””â”€ Test charge: Create test charge in Stripe dashboard
  â””â”€ Verify webhook delivery: Check Stripe dashboard â†’ Webhooks

â˜ Test AWS S3 Upload
  â””â”€ curl -X POST http://localhost:8000/api/files/upload \
     -H "Authorization: Bearer <test_token>" \
     -F "file=@test.jpg"
  â””â”€ Expected: 200 OK + file_id, cdn_url

â˜ Test Firebase Push Notifications
  â””â”€ python -c "from backend.services.fcm_service import FCMService; FCMService.test_connection()"
  â””â”€ Expected: Connection successful
```

---

## PHASE 7: WebSocket & REAL-TIME (5 minutes)

```
â˜ Test WebSocket connection
  â””â”€ python -c "import socketio; client = socketio.Client(); client.connect('http://localhost:8000'); print('Connected')"
  â””â”€ Expected: Connected message

â˜ Verify namespace availability
  â””â”€ Check: SNS namespace (/sns), Orders (/orders), Chat (/chat), Notifications (/notifications)

â˜ Test real-time event
  â””â”€ Create a post via API
  â””â”€ Listen to /sns namespace for post:created event
  â””â”€ Expected: Event received within 1 second
```

---

## PHASE 8: ELASTICSEARCH INDEXING (5 minutes)

```
â˜ Index all existing posts
  â””â”€ python backend/scripts/index_elasticsearch.py --posts

â˜ Index all existing reviews
  â””â”€ python backend/scripts/index_elasticsearch.py --reviews

â˜ Index all existing users
  â””â”€ python backend/scripts/index_elasticsearch.py --users

â˜ Verify indexing
  â””â”€ curl -X GET http://localhost:9200/_cat/indices?v
  â””â”€ Expected: 3 indices with > 0 docs

â˜ Test search
  â””â”€ curl -X POST http://localhost:9200/softfactory_posts/_search -d '{"query": {"match": {"content": "test"}}}'
  â””â”€ Expected: Relevant results
```

---

## PHASE 9: MONITORING & ALERTING (10 minutes)

### Prometheus

```
â˜ Install Prometheus
  â””â”€ Docker: docker run -d -p 9090:9090 -v prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus

â˜ Configure scrape targets
  â””â”€ API: localhost:8000/metrics
  â””â”€ PostgreSQL: postgresql exporter
  â””â”€ Redis: redis exporter
  â””â”€ Elasticsearch: elasticsearch exporter

â˜ Test metrics collection
  â””â”€ curl http://localhost:9090/api/v1/query?query=up
  â””â”€ Expected: All targets = 1 (up)
```

### Grafana

```
â˜ Install Grafana
  â””â”€ Docker: docker run -d -p 3000:3000 grafana/grafana

â˜ Add Prometheus data source
  â””â”€ URL: http://prometheus:9090
  â””â”€ Test connection: OK

â˜ Import dashboards
  â””â”€ PostgreSQL (ID: 9628)
  â””â”€ Redis (ID: 11835)
  â””â”€ Elasticsearch (ID: 14682)

â˜ Create custom dashboard
  â””â”€ API Response Time (p95, p99)
  â””â”€ Error Rate
  â””â”€ Database Connections
  â””â”€ Redis Memory Usage
```

### Alerts

```
â˜ Configure alerting rules
  â””â”€ High error rate (>5%)
  â””â”€ Database connection pool exhausted
  â””â”€ Elasticsearch unhealthy
  â””â”€ Redis memory usage >90%
  â””â”€ API response time >5s

â˜ Set up alert channels
  â””â”€ Email notifications
  â””â”€ Slack integration (optional)
  â””â”€ SMS alerts (for critical)
```

---

## PHASE 10: n8n WORKFLOW AUTOMATION (20 minutes)

```
â˜ Deploy n8n instance
  â””â”€ Docker: docker run -d -p 5678:5678 n8nio/n8n
  â””â”€ Or: n8n start

â˜ Access n8n UI
  â””â”€ URL: http://localhost:5678
  â””â”€ Set admin credentials (N8N_BASIC_AUTH_USER, N8N_BASIC_AUTH_PASSWORD)

â˜ Configure API endpoint nodes
  â””â”€ Create HTTP request node for Flask API
  â””â”€ Test connection: GET /api/health
  â””â”€ Expected: 200 OK

â˜ Create initial workflows
  â”œâ”€ User Registration (POST /register â†’ Send welcome email)
  â”œâ”€ SNS Post Scheduler (Hourly trigger â†’ Post to platforms)
  â”œâ”€ Payment Processing (Stripe webhook â†’ Update invoice)
  â”œâ”€ Review Scraping (Hourly â†’ Scrape listings â†’ Store results)
  â””â”€ See N8N_INTEGRATION_GUIDE.md section 7 for details

â˜ Set up webhook triggers
  â””â”€ Stripe webhook: https://yourdomain.com/api/payment/webhook
  â””â”€ Custom webhooks for internal workflows

â˜ Test workflow execution
  â””â”€ Trigger workflow manually
  â””â”€ Verify output logs
  â””â”€ Check database for expected changes
```

---

## PHASE 11: SMOKE TESTS (15 minutes)

### Health Checks

```bash
#!/bin/bash

echo "=== SoftFactory Production Smoke Tests ==="

# API Health
echo "1. API Health Check..."
curl -s http://localhost:8000/api/health | jq .
[ $? -eq 0 ] && echo "âœ“ API OK" || echo "âœ— API FAILED"

# Database
echo "2. Database Connection..."
curl -s -H "Authorization: Bearer demo_token" http://localhost:8000/api/auth/user
[ $? -eq 0 ] && echo "âœ“ Database OK" || echo "âœ— Database FAILED"

# Redis
echo "3. Redis Connection..."
redis-cli ping
[ $? -eq 0 ] && echo "âœ“ Redis OK" || echo "âœ— Redis FAILED"

# Elasticsearch
echo "4. Elasticsearch..."
curl -s http://localhost:9200/_health | jq .
[ $? -eq 0 ] && echo "âœ“ Elasticsearch OK" || echo "âœ— Elasticsearch FAILED"

# OAuth
echo "5. OAuth Google..."
curl -s "http://localhost:8000/api/auth/oauth/google/url" | jq .
[ $? -eq 0 ] && echo "âœ“ OAuth OK" || echo "âœ— OAuth FAILED"

# Stripe
echo "6. Payment Plans..."
curl -s "http://localhost:8000/api/payment/plans" | jq .
[ $? -eq 0 ] && echo "âœ“ Stripe OK" || echo "âœ— Stripe FAILED"

# S3
echo "7. File Upload..."
curl -s -X POST http://localhost:8000/api/files/upload \
  -H "Authorization: Bearer demo_token" \
  -F "file=@test.txt"
[ $? -eq 0 ] && echo "âœ“ S3 OK" || echo "âœ— S3 FAILED"

# WebSocket
echo "8. WebSocket..."
python -c "import socketio; c = socketio.Client(); c.connect('http://localhost:8000'); print('OK')"
[ $? -eq 0 ] && echo "âœ“ WebSocket OK" || echo "âœ— WebSocket FAILED"

# Frontend
echo "9. Frontend..."
curl -s http://localhost:8000/ | grep -q "<!DOCTYPE html>"
[ $? -eq 0 ] && echo "âœ“ Frontend OK" || echo "âœ— Frontend FAILED"

# n8n
echo "10. n8n..."
curl -s http://localhost:5678/ | grep -q "n8n"
[ $? -eq 0 ] && echo "âœ“ n8n OK" || echo "âœ— n8n FAILED"

echo "=== All Smoke Tests Complete ==="
```

### Functional Tests

```
â˜ User Registration Flow
  â””â”€ POST /api/auth/register â†’ verify email â†’ click link â†’ login
  â””â”€ Expected: JWT tokens issued

â˜ OAuth Login Flow
  â””â”€ GET /api/auth/oauth/google/url â†’ authorize â†’ callback â†’ redirect
  â””â”€ Expected: User created, JWT tokens issued

â˜ SNS Post Creation
  â””â”€ POST /api/sns/posts â†’ verify content â†’ schedule â†’ publish
  â””â”€ Expected: Post visible on platform

â˜ Payment Processing
  â””â”€ POST /api/payment/subscribe â†’ enter card â†’ charge â†’ verify subscription
  â””â”€ Expected: Invoice generated, subscription active

â˜ Review Scraping
  â””â”€ POST /api/review/scrape/now â†’ wait for completion â†’ check results
  â””â”€ Expected: Listings aggregated, displayed in UI

â˜ Search Function
  â””â”€ POST /api/search/full-text â†’ enter query â†’ get results
  â””â”€ Expected: Results ranked by relevance

â˜ Admin Dashboard
  â””â”€ Login as admin â†’ access /admin â†’ view KPIs
  â””â”€ Expected: All metrics loaded, no errors

â˜ Real-time Notification
  â””â”€ Create post â†’ listen to WebSocket â†’ verify event received
  â””â”€ Expected: Event within 1 second
```

---

## PHASE 12: BACKUP & DISASTER RECOVERY (5 minutes)

```
â˜ Verify database backup
  â””â”€ pg_dump softfactory > /backups/final_backup.sql
  â””â”€ Test restore: createdb softfactory_test && psql softfactory_test < /backups/final_backup.sql
  â””â”€ Verify: SELECT COUNT(*) FROM users; (should match production)

â˜ Store backups offsite
  â””â”€ Upload to S3 or secure cloud storage
  â””â”€ Keep last 30 days of daily backups
  â””â”€ Keep last 12 months of weekly backups

â˜ Document disaster recovery procedure
  â””â”€ How to restore database
  â””â”€ How to restore S3 files
  â””â”€ How to restore Elasticsearch indices
  â””â”€ RTO (Recovery Time Objective): < 1 hour
  â””â”€ RPO (Recovery Point Objective): < 1 day

â˜ Test disaster recovery (dry run)
  â””â”€ Simulate database failure
  â””â”€ Restore from backup
  â””â”€ Verify all systems operational
```

---

## PHASE 13: SECURITY HARDENING (10 minutes)

```
â˜ Enable HTTPS/SSL
  â””â”€ All traffic redirected HTTP â†’ HTTPS
  â””â”€ HSTS header enabled: max-age=31536000

â˜ API Key Security
  â””â”€ Stripe keys: never logged, never sent to frontend
  â””â”€ OAuth secrets: rotated quarterly
  â””â”€ Database password: unique, strong (min 16 chars)

â˜ Database Security
  â””â”€ User accounts: least privilege (read-only where possible)
  â””â”€ Network: only from application server
  â””â”€ Backups: encrypted at rest

â˜ Application Security
  â””â”€ CORS: only trusted origins
  â””â”€ CSRF protection: enabled for state-changing requests
  â””â”€ SQL injection: ORM protection, parameterized queries
  â””â”€ XSS protection: input validation, output encoding

â˜ Infrastructure Security
  â””â”€ Firewall: restrictive inbound rules
  â””â”€ SSH: key-based auth, no password login
  â””â”€ Secrets: never in code, use .env
  â””â”€ Logs: no sensitive data logged

â˜ Dependency Security
  â””â”€ pip audit: scan for known vulnerabilities
  â””â”€ npm audit: scan for npm vulnerabilities
  â””â”€ Regular updates: monthly security patches
```

---

## PHASE 14: FINAL VALIDATION & GO-LIVE (10 minutes)

```
â˜ Stakeholder Sign-off
  â””â”€ Business stakeholders: all features verified working
  â””â”€ Technical team: all systems healthy
  â””â”€ Product manager: deployment approved
  â””â”€ Security: no critical issues

â˜ Load Testing (optional but recommended)
  â””â”€ Use k6 to simulate 100+ concurrent users
  â””â”€ Target latency: <1 second for API calls
  â””â”€ Expected throughput: 1000+ requests/second

â˜ Performance Baseline
  â””â”€ Document current response times:
     - API endpoints: <500ms (p95)
     - Search queries: <100ms
     - File uploads: <5 seconds for 10MB
     - Database queries: <50ms
  â””â”€ Set alerts if metrics exceed 2x baseline

â˜ Create incident response runbook
  â””â”€ How to handle API downtime
  â””â”€ How to handle database issues
  â””â”€ How to handle payment processing failure
  â””â”€ Emergency contacts list
  â””â”€ Post-incident review template

â˜ Schedule on-call rotation
  â””â”€ 24/7 monitoring during first 30 days
  â””â”€ Page on-call for critical alerts
  â””â”€ Daily standup to review issues

â˜ Deploy to production
  â””â”€ docker-compose up -d (if using Docker)
  â””â”€ systemctl restart softfactory (if systemd)
  â””â”€ Monitor logs for first 1 hour
  â””â”€ Verify all alerts working
```

---

## POST-DEPLOYMENT MONITORING (Next 7 Days)

```
Day 1:
  â˜ Monitor error rates (target: <0.1%)
  â˜ Monitor response times (target: <500ms p95)
  â˜ Check database query performance
  â˜ Verify all scheduled jobs running
  â˜ Review Sentry for new issues

Day 2-7:
  â˜ Daily standup: discuss any incidents
  â˜ Monitor user feedback
  â˜ Review analytics for unusual patterns
  â˜ Verify backups completing successfully
  â˜ Performance trending (should be stable)

Week 2-4:
  â˜ Switch from 24/7 on-call to business hours
  â˜ Analyze usage patterns
  â˜ Optimize slow queries based on real data
  â˜ Update runbooks based on learnings
  â˜ Plan for scaling if needed
```

---

## ROLLBACK PLAN

If critical issues occur post-deployment:

```
Severity: CRITICAL (>50% users affected)
  â˜ Immediate: Revert to previous Docker image tag
  â˜ Command: docker-compose down && docker-compose up -d
  â˜ Expected downtime: <5 minutes
  â˜ Notify users: Post status on status page

Severity: HIGH (1-50% users affected)
  â˜ Analyze issue (15 minutes max)
  â˜ Attempt fix if straightforward
  â˜ Otherwise: rollback to previous version
  â˜ Schedule post-mortem within 24 hours

Severity: MEDIUM (specific feature broken)
  â˜ Disable feature (if possible)
  â˜ Develop fix in hotfix branch
  â˜ Deploy fix in next 1-2 hours
  â˜ No rollback needed if feature is isolated
```

---

## DEPLOYMENT SUMMARY

| Phase | Duration | Critical? | Status |
|-------|----------|-----------|--------|
| Pre-deployment | 15 min | YES | â˜ |
| Database setup | 10 min | YES | â˜ |
| Redis setup | 5 min | YES | â˜ |
| Elasticsearch | 15 min | NO | â˜ |
| Flask API | 10 min | YES | â˜ |
| Nginx proxy | 10 min | YES | â˜ |
| OAuth setup | 10 min | YES | â˜ |
| WebSocket | 5 min | NO | â˜ |
| Elasticsearch indexing | 5 min | NO | â˜ |
| Monitoring | 10 min | NO | â˜ |
| n8n workflows | 20 min | NO | â˜ |
| Smoke tests | 15 min | YES | â˜ |
| Backup & DR | 5 min | YES | â˜ |
| Security | 10 min | YES | â˜ |
| Final validation | 10 min | YES | â˜ |
| **TOTAL** | **145 min** | | |

---

**Deployment Date:** [INSERT DATE]
**Deployed By:** [NAME]
**Approved By:** [MANAGER]
**Time Started:** [TIME]
**Time Completed:** [TIME]
**Outcome:** â˜ SUCCESS â˜ PARTIAL SUCCESS â˜ ROLLBACK

**Post-Deployment Notes:**
[Space for notes and issues encountered]

---

**For support:** See DAILY_OPERATIONS_GUIDE.md
**For architecture:** See N8N_INTEGRATION_GUIDE.md
**For API reference:** See API_ENDPOINT_QUICK_REFERENCE.md