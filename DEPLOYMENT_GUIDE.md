# SoftFactory Deployment Guide

Fact Source: `docs/FACTS_SNAPSHOT_LATEST.json` (generated by `python scripts/generate_facts_snapshot.py`).

Updated: 2026-02-26

This guide reflects current executable code and workflow files.

## Phase 2~8 Roadmap

Current Phase 1 is complete. Next steps:

### Phase 2: Test Data Expansion (30 min)

```bash
python populate_test_data.py
```

Results: 20 SNS posts, 50 recipes, 30 reviews, 5 SNS accounts for testing

### Phase 3: Elasticsearch Integration (45 min)

```bash
docker compose up elasticsearch
curl -X GET "localhost:9200/_cluster/health"
```

### Phase 4: Docker Compose Full Stack (1 hour)

```bash
docker compose config  # Validate
docker compose up      # Run
```

### Phase 5: Environment Configuration (30 min)

- Create `.env` file (copy from `.env.example`)
- Configure GitHub Secrets for CI/CD

### Phase 6: Deployment Guide (2 hours)

Local testing followed by staging/production deployment

### Phase 7: CI/CD Pipeline (1.5 hours)

GitHub Actions workflow validation

### Phase 8: Monitoring Setup (1.5 hours)

Prometheus + Grafana + alerting configuration

## GitHub Secrets Configuration

Go to GitHub Repository > Settings > Secrets and variables > Actions and add:

| Key | Value | Required By |
|-----|-------|-------------|
| DOCKER_USERNAME | Docker Hub username | deploy-production, deploy-staging |
| DOCKER_PASSWORD | Docker Hub password | deploy-production, deploy-staging |
| PRODUCTION_HOST | Production server IP/hostname | deploy-production |
| PRODUCTION_USER | Production SSH user (e.g., ubuntu) | deploy-production |
| PRODUCTION_SSH_KEY | Production SSH private key | deploy-production |
| STAGING_HOST | Staging server IP/hostname | deploy-staging |
| STAGING_USER | Staging SSH user (e.g., ubuntu) | deploy-staging |
| STAGING_SSH_KEY | Staging SSH private key | deploy-staging |
| DEPLOY_HOST | Legacy deployment server IP | deploy.yml |
| DEPLOY_KEY | Legacy deployment SSH key | deploy.yml |
| TELEGRAM_BOT_TOKEN | Telegram Bot Token | Deployment notifications |
| TELEGRAM_CHAT_ID | Telegram Chat ID | Deployment notifications |
| CODECOV_TOKEN | Codecov Token | ci.yml (optional) |

### Setting SSH Keys

To convert your SSH private key for GitHub Secrets:

```bash
# For multi-line keys, ensure newlines are preserved as literal \n
cat ~/.ssh/id_rsa | jq -Rs .
```

Then paste the output into GitHub Secrets.

## Local Testing

Before deploying to production:

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Initialize database
python -c "from backend.app import create_app, init_db; app = create_app(); init_db()"

# 3. Load test data
python init_test_data.py

# 4. Run server
python run.py

# 5. Test API endpoints
curl -X GET http://localhost:8000/api/coocook/chefs
curl -X GET http://localhost:8000/health
```

## Production Checklist

Before production deployment:

- [ ] All packages in `requirements.txt`
- [ ] Docker image builds successfully
- [ ] `docker compose config` passes validation
- [ ] `.env` file configured with all required variables
- [ ] GitHub Secrets configured (see above)
- [ ] Local tests passing
- [ ] Security checks passing (`security.yml`)
- [ ] Health endpoint responds with 200
- [ ] Core auth flow verified
- [ ] One endpoint tested from each service (payment, sns, files, search)
- [ ] Error monitoring and alerts active
- [ ] Rollback plan documented

## 1. Deployment Modes

### A) Local API development

```bash
python run.py
```

- Host: `127.0.0.1`
- Port: `8000`
- Health: `http://127.0.0.1:8000/health`

### B) Integrated demo runtime

```bash
python start_platform.py
```

- Host: `0.0.0.0`
- Port: `9000`
- Web entry: `http://localhost:9000/web/platform/index.html`

### C) Docker local stack

```bash
docker-compose up -d --build
```

- API: `http://localhost:8000`
- PostgreSQL: `localhost:5432`
- Redis: `localhost:6379`

### D) Vercel production frontend

- Requirements: backend already reachable at a public URL.
- Configuration:
  - Add environment variable in Vercel: `API_UPSTREAM_URL=<backend public origin>`
  - Example: `API_UPSTREAM_URL=https://your-backend.example.com`
- Routing is configured in `vercel.json`:
  - `/platform/*` served from `web/platform/*`
  - root and other pages mapped from `web/*`
  - `/api/*` proxied through `api/proxy.js`

Deployment command:

```bash
npx vercel --prod --yes
```

## 2. Required Environment Inputs

Start from:

```bash
cp .env.example .env
```

Minimum production categories:

- `DATABASE_URL`
- `JWT_SECRET` and `PLATFORM_SECRET_KEY`
- OAuth credentials (`GOOGLE_*`, `FACEBOOK_*`, `KAKAO_*`)
- Payment keys (`STRIPE_*`)
- Storage keys (`AWS_*`)
- Monitoring (`SENTRY_DSN`)
- Messaging (`TELEGRAM_*`)

## 3. Canonical CI/CD Workflows

Use these as primary paths:

- CI checks: `.github/workflows/ci.yml`
- Staging deploy: `.github/workflows/deploy-staging.yml`
- Production deploy: `.github/workflows/deploy-production.yml`

Legacy/alternative workflows exist in the repo; treat them as non-canonical unless explicitly selected by operations.

## 4. Production Safety Controls

Before production rollout:

1. Run full CI and confirm green state.
2. Validate `/health` and `/api/admin/metrics` in target environment.
3. Use staged deployment with health checks.
4. Keep rollback image/tag available.
5. Do not ship with demo/default secrets.

## 5. Post-Deploy Verification

Verify at minimum:

- Health endpoint returns 200.
- Core auth flow works.
- One endpoint each from payment, sns, files, and search returns expected auth/status behavior.
- Error monitoring and alert channels are active.

## 6. Operational Note

The repository contains many historical delivery reports. For current deployment truth, follow executable scripts and workflow files first, then this guide.

---

# Phase 6: Detailed Deployment Guide (Extended)

## 1. 로컬 개발 환경 설정

### 1.1 사전 요구사항

- **Python:** 3.11+ (required)
- **Docker:** 24.0+ (for containerization)
- **Docker Compose:** 2.20+ (for multi-container orchestration)
- **Git:** 2.34+ (for version control)
- **Node.js:** 18.0+ (optional, for frontend development)
- **PostgreSQL client:** psql (optional, for direct DB access)
- **Redis CLI:** redis-cli (optional, for cache inspection)

**System Requirements:**
- RAM: Minimum 8GB (16GB recommended for Docker)
- Disk: 10GB free space for Docker images and data
- Network: Stable internet for package downloads

### 1.2 의존성 설치

#### Step 1: Python 패키지 설치

```bash
# Clone repository
git clone https://github.com/yourusername/softfactory.git
cd softfactory

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Linux/macOS:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# (Optional) Install development dependencies
pip install -r requirements-dev.txt
```

**주요 패키지:**
- Flask 2.3+
- SQLAlchemy 2.0+
- PyJWT for authentication
- requests for HTTP calls
- python-dotenv for environment variables

#### Step 2: 데이터베이스 초기화

```bash
# Initialize SQLite database (development)
python -c "from backend.app import create_app, init_db; app = create_app(); init_db()"

# Or with Flask CLI
export FLASK_APP=backend/app.py
flask db upgrade

# Verify database creation
ls -lh platform.db
```

**Expected Output:**
```
platform.db                    # SQLite database file created
platform.db-shm               # Shared memory file (can be ignored)
platform.db-wal               # Write-ahead log (can be ignored)
```

#### Step 3: 테스트 데이터 로드

```bash
# Load basic test data (3 products, 1 subscription, 1 SNS account)
python init_test_data.py

# Expected output:
# Created 3 products, 1 subscription, 1 SNS account in database

# Load expanded test data (50+ recipes, 20+ posts, etc.)
python populate_test_data.py

# This takes ~30 seconds, creates:
# - 50 recipes
# - 20 SNS posts
# - 30 reviews
# - 5 SNS accounts
```

### 1.3 로컬 서버 실행

#### 방법 A: Flask 개발 서버 (간단함)

```bash
# Set development environment
export FLASK_ENV=development
export DEBUG=true
export TESTING=false

# Run development server
python run.py

# Server starts on http://localhost:8000
# Auto-reload enabled for code changes
# Full debug mode for error tracking
```

**출력:**
```
 * Serving Flask app 'backend.app'
 * Debug mode: on
 * WARNING in app.run_simple, line 906, in run (...)
 * Running on http://127.0.0.1:8000
```

**접근 URL:**
- API: http://localhost:8000
- Health: http://localhost:8000/health
- Admin: http://localhost:8000/api/admin

#### 방법 B: Platform 통합 서버 (전체 UI 포함)

```bash
# Run integrated platform with frontend
python start_platform.py

# Server starts on http://localhost:9000
# Includes web UI at http://localhost:9000/web/platform/
```

#### 방법 C: Docker로 실행 (권장)

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your settings (see Section 2)
nano .env

# Build and start all services
docker compose up -d --build

# Check service status
docker compose ps

# View logs
docker compose logs -f api
```

**Service Status (Expected):**
```
NAME                    STATUS
softfactory-api         Up (healthy)
softfactory-postgres    Up (healthy)
softfactory-redis       Up (healthy)
softfactory-elasticsearch Up (healthy)
```

**Service Ports:**
| Service | Port | URL |
|---------|------|-----|
| Flask API | 8000 | http://localhost:8000 |
| PostgreSQL | 5432 | localhost:5432 |
| Redis | 6379 | localhost:6379 |
| Elasticsearch | 9200 | http://localhost:9200 |
| pgAdmin | 5050 | http://localhost:5050 |
| Prometheus | 9090 | http://localhost:9090 |
| Grafana | 3000 | http://localhost:3000 |
| Alertmanager | 9093 | http://localhost:9093 |

### 1.4 헬스 체크

```bash
# API health check
curl -s http://localhost:8000/health | jq .

# Expected response:
{
  "status": "healthy",
  "version": "1.0.0",
  "timestamp": "2026-02-27T10:30:00Z",
  "services": {
    "database": "healthy",
    "redis": "healthy",
    "elasticsearch": "healthy"
  }
}

# Database connectivity check
curl -s http://localhost:8000/api/admin/db-check | jq .

# Cache connectivity check
curl -s http://localhost:8000/api/admin/cache-check | jq .
```

---

## 2. 테스트 전략

### 2.1 단위 테스트 (Unit Tests)

```bash
# Run all unit tests
pytest tests/unit/ -v

# Run specific test file
pytest tests/unit/test_models.py -v

# Run with coverage
pytest tests/unit/ --cov=backend --cov-report=html

# Coverage report
open htmlcov/index.html
```

**기대 결과:**
- 모든 테스트 PASS
- 커버리지 >= 80%
- 실행 시간 < 30초

### 2.2 통합 테스트 (Integration Tests)

```bash
# Run integration tests
pytest tests/integration/ -v

# Run with fixtures and database
pytest tests/integration/test_api_endpoints.py -v --tb=short

# With coverage report
pytest tests/integration/ \
  --cov=backend \
  --cov-report=html \
  --cov-report=term-missing
```

**테스트 항목:**
- API endpoint connectivity
- Database transaction handling
- Authentication flow
- Service integration
- Error handling

### 2.3 E2E 테스트 (End-to-End Tests)

```bash
# Run E2E tests
pytest tests/e2e/ -v

# Run with headless browser (requires Puppeteer/Selenium)
pytest tests/e2e/ -v --headless

# Run user journey tests
pytest tests/e2e/test_user_journeys.py -v
```

**대상:**
- 완전한 사용자 흐름 (가입, 로그인, 기능 사용)
- 크로스 서비스 상호작용
- UI 렌더링 확인

### 2.4 API 엔드포인트 테스트

```bash
# Quick API test script (provided)
python test_endpoints.py

# Manual curl tests
# 1. Health check
curl -v http://localhost:8000/health

# 2. Authentication
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "Test123456!"
  }'

# 3. Get JWT token from response
TOKEN="your_jwt_token_here"

# 4. CooCook API (recipes)
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8000/api/coocook/chefs

# 5. SNS API (social media)
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8000/api/sns/accounts

# 6. Review API
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8000/api/review/recipes

# 7. Search API
curl "http://localhost:8000/api/search?q=recipe&limit=10"

# 8. Admin metrics
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8000/api/admin/metrics
```

**Expected Responses:**
| Endpoint | Status | Notes |
|----------|--------|-------|
| /health | 200 | Should be instant |
| /api/auth/login | 200 | Returns JWT token |
| /api/coocook/chefs | 200 | Requires auth |
| /api/sns/accounts | 200 | Requires auth |
| /api/search | 200 | No auth required |

### 2.5 성능 테스트 (Load Test)

```bash
# Install load testing tool
pip install locust

# Run load test
locust -f locustfile.py --host=http://localhost:8000

# Or use Apache Bench
ab -n 1000 -c 10 http://localhost:8000/health

# Results:
# - Requests per second: >= 100
# - 95% response time: < 500ms
# - Error rate: < 1%
```

---

## 3. 배포 환경별 설정

### 3.1 Staging 환경

#### 3.1.1 GitHub Secrets 설정

Staging 배포를 위해 GitHub Repository > Settings > Secrets에 다음을 추가:

```
STAGING_HOST = staging.yourdomain.com
STAGING_USER = deploy
STAGING_SSH_KEY = (private SSH key in PEM format)
DOCKER_USERNAME = your_docker_username
DOCKER_PASSWORD = your_docker_password_or_token
```

#### 3.1.2 배포 트리거

```bash
# Push to develop branch triggers staging deployment
git checkout develop
git commit -m "Feature: new feature"
git push origin develop

# Or manual trigger via GitHub UI:
# GitHub Actions > deploy-staging > Run workflow
```

#### 3.1.3 배포 프로세스

자동으로 다음이 실행됨:

```
1. CI 파이프라인 (단위 테스트, 린트, 보안 검사)
   ↓ (5-10분)
2. Docker 이미지 빌드 및 Docker Hub에 push
   ↓ (3-5분)
3. Staging 서버 SSH 연결
   ↓
4. 이전 컨테이너 중지 및 제거
   ↓
5. 신규 Docker 이미지 pull
   ↓
6. 데이터베이스 마이그레이션 (필요시)
   ↓
7. 신규 서비스 시작
   ↓
8. 헬스 체크 (3회 재시도, 10초 간격)
   ↓ (성공)
9. Telegram 알림 전송
   ↓
배포 완료 (약 20-30분)
```

#### 3.1.4 배포 후 검증

```bash
# SSH into staging server
ssh deploy@staging.yourdomain.com

# Check service status
docker compose ps

# View logs
docker compose logs -f api

# Test endpoints
curl https://staging.yourdomain.com/health
curl https://staging.yourdomain.com/api/coocook/chefs

# Monitor for 5-10 minutes
# Check error rates in monitoring dashboard
```

**Staging 접근:**
- URL: https://staging.yourdomain.com
- 헬스 체크: https://staging.yourdomain.com/health
- 모니터링: https://staging.yourdomain.com/prometheus (if exposed)

### 3.2 Production 환경

#### 3.2.1 Production Secrets 설정

```
PRODUCTION_HOST = api.yourdomain.com
PRODUCTION_USER = deploy
PRODUCTION_SSH_KEY = (private SSH key in PEM format)
DOCKER_USERNAME = your_docker_username
DOCKER_PASSWORD = your_docker_password_or_token
TELEGRAM_BOT_TOKEN = (for notifications)
TELEGRAM_CHAT_ID = (for notifications)
```

#### 3.2.2 배포 옵션 A: 자동 배포 (Main branch push)

```bash
# Create release on main branch
git checkout main
git merge develop  # Merge staging code
git push origin main

# Automatic production deployment starts
# (requires manual approval in GitHub Actions)
```

**절차:**
1. GitHub Actions 워크플로 시작
2. 모든 CI 검사 실행
3. "승인 필요" 메뉴 표시
4. 승인자가 GitHub UI에서 승인
5. 배포 진행

#### 3.2.3 배포 옵션 B: 태그 기반 배포 (Release)

```bash
# Create release tag
git tag -a v1.0.0 -m "Production Release v1.0.0"
git push origin v1.0.0

# GitHub Actions automatically triggers production deployment
```

#### 3.2.4 Canary 배포 (점진적 롤아웃)

```yaml
# .github/workflows/deploy-production.yml에 설정됨

1. Pre-flight checks
   - 디스크 용량 >= 20%
   - 네트워크 연결성 확인

2. Canary deployment (10% traffic)
   - 신규 버전으로 10% 트래픽 라우팅
   - 5분 모니터링

3. Health check
   - 에러율 < 1% → 전체 배포
   - 에러율 >= 1% → 자동 롤백

4. Full rollout
   - 100% 트래픽을 신규 버전으로 라우팅

5. Post-deployment
   - 최종 헬스 체크
   - Slack/Telegram 알림
```

#### 3.2.5 롤백 절차

```bash
# SSH into production server
ssh deploy@api.yourdomain.com

# Check docker images
docker images | grep softfactory

# Rollback to previous version
docker pull softfactory:v1.0.0-stable
docker compose -f docker-compose.prod.yml up -d

# Verify
curl https://api.yourdomain.com/health

# Monitor
docker compose logs -f api
```

**롤백 자동 트리거:**
- 에러율 >= 1% (Canary 배포 중)
- 헬스 체크 실패
- 중요 서비스 미응답 (5초 이상)

#### 3.2.6 Production 모니터링

```bash
# Prometheus metrics
curl https://api.yourdomain.com/metrics

# Error tracking (Sentry)
https://sentry.io/organizations/yourorg/issues/

# Logs (CloudWatch/ELK)
# Access via monitoring dashboard

# Alert channels
- Slack: #prod-alerts
- Telegram: +1234567890
- Email: ops@yourdomain.com
```

---

## 4. 성능 최적화

### 4.1 Redis 캐싱 최적화

```bash
# Redis 메모리 상태 확인
redis-cli INFO memory

# Expected output:
used_memory_human:245.50M
used_memory_peak_human:245.50M
maxmemory:512M

# 캐시 통계 조회
curl http://localhost:8000/api/perf/cache-stats

# 응답:
{
  "hits": 45230,
  "misses": 1203,
  "hit_rate": 0.974,
  "memory_used": "245MB",
  "evictions": 23
}

# 메모리가 가득 차면 정책 조정
redis-cli CONFIG SET maxmemory-policy allkeys-lru

# 개별 캐시 삭제
redis-cli DEL cache_key_name

# 전체 캐시 초기화 (주의!)
redis-cli FLUSHDB
```

**최적화 팁:**
- 자주 접근하는 데이터는 높은 TTL 설정
- 사용자별 캐시는 짧은 TTL (5분)
- 마스터 데이터는 긴 TTL (1시간)

### 4.2 Elasticsearch 성능

```bash
# 클러스터 상태 확인
curl http://localhost:9200/_cluster/health?pretty

# Expected:
{
  "status": "green",
  "active_shards": 5,
  "active_primary_shards": 5
}

# 인덱스 상태 및 크기
curl http://localhost:9200/_cat/indices?format=json | jq '.[] | {index, docs, size}'

# Sample output:
[
  {
    "index": "recipes",
    "docs": "50000",
    "size": "125MB"
  }
]

# 샤드 분배 확인
curl http://localhost:9200/_cat/shards

# 쿼리 성능 분석
curl -X POST http://localhost:9200/recipes/_search \
  -H 'Content-Type: application/json' \
  -d '{
    "query": {"match": {"title": "pasta"}},
    "took_millis": 0
  }'

# 인덱스 최적화 (메모리 절약)
curl -X POST http://localhost:9200/recipes/_forcemerge?max_num_segments=1

# 오래된 인덱스 삭제
curl -X DELETE http://localhost:9200/recipes-2026-01
```

**성능 기준:**
- 검색 응답시간: < 100ms
- 인덱싱 처리량: > 5000 docs/sec
- 샤드 상태: STARTED (모두)
- 클러스터 상태: GREEN

### 4.3 데이터베이스 최적화

```bash
# PostgreSQL 쿼리 성능 (프로덕션에서 활성화)
psql -U postgres -c "SET log_min_duration_statement = 1000;" -d softfactory

# MySQL 슬로우 쿼리 로그
mysql> SET GLOBAL slow_query_log = 'ON';
mysql> SET GLOBAL long_query_time = 2;

# 인덱스 상태 확인
psql -U postgres -d softfactory -c "\d+ recipes"

# 테이블 크기 확인
psql -U postgres -d softfactory -c "SELECT schemaname, tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename))
  FROM pg_tables ORDER BY pg_total_relation_size DESC LIMIT 10;"

# 쿼리 실행 계획 분석
EXPLAIN ANALYZE SELECT * FROM recipes WHERE title LIKE '%pasta%';

# 통계 갱신 (인덱스 최적화)
ANALYZE;

# Vacuum (디스크 최적화)
VACUUM ANALYZE;
```

**최적화 팁:**
- 자주 필터링되는 컬럼에 인덱스 생성
- 복합 조건 쿼리는 복합 인덱스 사용
- 주기적으로 VACUUM ANALYZE 실행 (weekly)

### 4.4 애플리케이션 레벨 최적화

```bash
# Gunicorn 워커 최적화
gunicorn -w 4 -b 0.0.0.0:8000 \
  --worker-class sync \
  --timeout 60 \
  --max-requests 1000 \
  backend.app:app

# uWSGI 최적화
uwsgi --http :8000 \
  --wsgi-file backend/app.py \
  --master \
  --processes 4 \
  --threads 2 \
  --lazy-apps

# 성능 모니터링
curl http://localhost:8000/api/admin/metrics

# Expected metrics:
{
  "request_count": 45230,
  "avg_response_time_ms": 123,
  "p95_response_time_ms": 450,
  "p99_response_time_ms": 890,
  "error_rate": 0.002
}
```

### 4.5 모니터링 대시보드

#### Prometheus (메트릭 수집)

```bash
# Prometheus 접근
http://localhost:9090

# 자주 사용하는 쿼리:
http_request_duration_seconds{quantile="0.95"}  # p95 응답시간
rate(http_requests_total[5m])                   # 초당 요청 수
container_memory_usage_bytes                    # 컨테이너 메모리
```

#### Grafana (대시보드 시각화)

```bash
# Grafana 접근
http://localhost:3000

# 기본 계정: admin / admin

# 대시보드:
- Application Metrics
- Database Performance
- Redis Cache Stats
- Elasticsearch Health
- Docker Container Stats
```

#### Alertmanager (알림)

```bash
# Alertmanager 접근
http://localhost:9093

# 활성 알림 확인
curl http://localhost:9093/api/v1/alerts

# 알림 채널 설정 (Slack, Telegram, Email)
# 파일: monitoring/alertmanager.yml
```

---

## 5. 트러블슈팅

### 5.1 연결 오류 (Connection Refused)

**증상:** `Error: Connection refused on localhost:8000`

```bash
# 1. 서비스 상태 확인
docker compose ps

# Expected: All services should be "Up"

# 2. 서비스 로그 확인
docker compose logs api

# 3. 포트 충돌 확인
lsof -i :8000      # macOS/Linux
netstat -ano | findstr :8000  # Windows

# 4. 서비스 재시작
docker compose restart api

# 5. 전체 스택 재시작 (최후 수단)
docker compose down
docker compose up -d
```

### 5.2 데이터베이스 연결 오류

**증상:** `Error: connection failed: could not connect to server: Connection refused`

```bash
# 1. PostgreSQL 상태 확인
docker compose logs postgres

# 2. 포트 확인
docker compose port postgres 5432

# 3. 연결 테스트
psql -h localhost -U postgres -d softfactory -c "SELECT 1;"

# 4. 데이터베이스 재초기화
docker compose exec postgres psql -U postgres -c "DROP DATABASE softfactory;"
docker compose exec postgres psql -U postgres -c "CREATE DATABASE softfactory;"

# 5. 서비스 재시작
docker compose restart postgres
docker compose restart api
```

### 5.3 Elasticsearch 미준비 (Not Ready)

**증상:** `Elasticsearch cluster status: YELLOW`

```bash
# 1. 클러스터 상태 확인
curl http://localhost:9200/_cluster/health?pretty

# 2. 샤드 상태 확인
curl http://localhost:9200/_cat/shards

# 3. 로그 확인
docker compose logs elasticsearch

# 4. Elasticsearch 재시작
docker compose restart elasticsearch

# 5. 초기화 (데이터 손실!)
docker compose down -v
docker compose up -d elasticsearch
```

### 5.4 메모리 초과 오류

**증상:** `Container killed: OOMKilled`

```bash
# 1. 컨테이너 메모리 사용률 확인
docker stats softfactory-api

# 2. 메모리 제한 확인
docker inspect softfactory-api | grep -A 5 '"Memory"'

# 3. docker-compose.yml에서 메모리 제한 조정
# services.api.deploy.resources.limits.memory: 2g

# 4. 스택 재시작
docker compose down
docker compose up -d

# 5. 메모리 누수 디버그 (Python)
python -m memory_profiler backend/app.py
```

### 5.5 JWT 토큰 오류

**증상:** `401 Unauthorized: Invalid token`

```bash
# 1. 토큰 생성 테스트
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"Test123456!"}'

# 2. 토큰 검증
curl -H "Authorization: Bearer YOUR_TOKEN" \
  http://localhost:8000/api/coocook/chefs

# 3. JWT_SECRET 확인
echo $JWT_SECRET

# 4. 토큰 만료 확인
# JWT 디코더: https://jwt.io

# 5. 환경변수 다시 로드
docker compose restart api
```

### 5.6 권한 오류 (Permission Denied)

**증상:** `Permission denied: /data/platform.db`

```bash
# 1. 파일 권한 확인
ls -la platform.db

# 2. 권한 수정 (Linux/macOS)
chmod 644 platform.db
chmod 755 .

# 3. Docker 컨테이너 권한 확인
docker exec softfactory-api ls -la /data/

# 4. 볼륨 권한 수정
docker compose exec api chown -R app:app /data

# 5. 볼륨 재마운트
docker compose down -v
docker compose up -d
```

---

## 6. 배포 전 체크리스트

### 개발 단계
- [ ] 기능 개발 완료 (모든 요구사항 구현됨)
- [ ] 단위 테스트 작성 (>= 80% 커버리지)
- [ ] 단위 테스트 통과 (0 failures)
- [ ] 코드 리뷰 완료 (최소 1명)
- [ ] 린트 체크 통과 (flake8, mypy 0 warnings)
- [ ] 보안 검사 통과 (bandit 0 critical)

### 테스트 단계
- [ ] 통합 테스트 100% 통과
- [ ] E2E 테스트 실행 및 통과 (주요 사용자 흐름)
- [ ] 성능 테스트 실행 (응답시간 < 500ms)
- [ ] 보안 테스트 완료 (OWASP Top 10 검증)
- [ ] 접근성 테스트 (WAI-ARIA, screen reader)
- [ ] 호환성 테스트 (Chrome, Firefox, Safari)

### 배포 단계
- [ ] Docker 이미지 빌드 성공 (0 warnings)
- [ ] docker-compose config 검증 통과
- [ ] .env 파일 설정 완료 (모든 변수)
- [ ] GitHub Secrets 설정 완료
  - [ ] DOCKER_USERNAME
  - [ ] DOCKER_PASSWORD
  - [ ] STAGING_HOST / STAGING_USER / STAGING_SSH_KEY
  - [ ] PRODUCTION_HOST / PRODUCTION_USER / PRODUCTION_SSH_KEY
  - [ ] TELEGRAM_BOT_TOKEN / TELEGRAM_CHAT_ID
- [ ] 로컬 테스트 모두 통과
- [ ] CI 파이프라인 모두 green
- [ ] 데이터베이스 백업 완료
- [ ] 롤백 계획 수립 (이전 버전 태그)
- [ ] 모니터링 알림 설정 완료
- [ ] 운영팀 공지 완료

### 배포 후
- [ ] 헬스 체크 통과 (http://api.yourdomain.com/health → 200)
- [ ] 메인 엔드포인트 응답 확인 (API 응답 < 500ms)
- [ ] 에러 로그 확인 (새로운 에러 없음)
- [ ] 모니터링 대시보드 확인
  - [ ] CPU < 70%
  - [ ] 메모리 < 80%
  - [ ] 에러율 < 1%
  - [ ] 응답시간 p95 < 500ms
- [ ] 사용자 알림 (Slack, Telegram, Email)
- [ ] 배포 시간 기록 (추후 최적화)
- [ ] 배포 후보고서 작성

---

## 7. 배포 후보고서 템플릿

```markdown
# 배포 후보고서

**배포 날짜:** 2026-02-27
**배포 시간:** 10:30 ~ 10:45 (15분)
**배포자:** DevOps Team
**승인자:** CTO

## 배포 정보
- **버전:** v1.0.0
- **환경:** production
- **배포 방식:** Canary (10% → 100%)
- **이전 버전:** v0.9.9

## 배포 결과
- **상태:** SUCCESS ✅
- **헬스 체크:** PASS
- **롤백:** Not required
- **영향:** 0 users affected (no downtime)

## 메트릭
| 메트릭 | 목표 | 결과 | 상태 |
|--------|------|------|------|
| 배포 소요 시간 | < 30분 | 15분 | ✅ |
| 에러율 | < 1% | 0.1% | ✅ |
| p95 응답시간 | < 500ms | 234ms | ✅ |
| 메모리 사용률 | < 80% | 62% | ✅ |

## 변경사항
- Feature: OAuth integration (#45)
- Fix: SNS posting error (#46)
- Chore: Dependency updates

## 다음 단계
- [ ] 24시간 모니터링
- [ ] 사용자 피드백 수집
- [ ] 성능 최적화 검토
- [ ] 다음 배포 계획 (2026-03-06)
```

---

## 8. 배포 자동화 명령어 모음

```bash
# === Development ===
python run.py                          # 로컬 개발 서버 시작
python -m pytest                       # 모든 테스트 실행
python -m black backend/               # 코드 포맷팅

# === Docker ===
docker compose up -d                  # 전체 스택 시작
docker compose down                    # 전체 스택 중지
docker compose ps                      # 서비스 상태 확인
docker compose logs -f api             # API 로그 스트리밍

# === Database ===
python -c "from backend.app import create_app, init_db; app = create_app(); init_db()"  # DB 초기화
python init_test_data.py               # 기본 테스트 데이터 로드
python populate_test_data.py           # 대량 테스트 데이터 로드

# === Deployment ===
git push origin develop                # Staging 배포 트리거
git tag -a v1.0.0 -m "Release"        # Production 배포 트리거
git push origin v1.0.0                 # 태그 푸시 (배포 시작)

# === Monitoring ===
curl http://localhost:8000/health      # 헬스 체크
curl http://localhost:8000/metrics     # Prometheus 메트릭
curl http://localhost:9090             # Prometheus UI
curl http://localhost:3000             # Grafana UI
```

---

## 9. 참고 자료

- [Flask Deployment Guide](https://flask.palletsprojects.com/en/2.3.x/deploying/)
- [Docker Compose Reference](https://docs.docker.com/compose/compose-file/)
- [GitHub Actions Workflows](https://docs.github.com/en/actions/using-workflows)
- [PostgreSQL Performance](https://www.postgresql.org/docs/current/performance.html)
- [Elasticsearch Best Practices](https://www.elastic.co/guide/en/elasticsearch/reference/current/how-to.html)
- [Prometheus Monitoring](https://prometheus.io/docs/prometheus/latest/getting_started/)
- [Grafana Dashboards](https://grafana.com/docs/grafana/latest/dashboards/)


