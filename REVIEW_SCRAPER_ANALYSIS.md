# Review Scraper - 5ê°œ í”Œë«í¼ í†µí•© ë¶„ì„ ë³´ê³ ì„œ

**ì‘ì„±ì¼:** 2026-02-26
**ìƒíƒœ:** êµ¬í˜„ ì™„ë£Œ (95%) - ë§ˆì´ë„ˆ ê°œì„  í•„ìš”
**í† í° ì‚¬ìš©:** ~80K / 200K (40%)

---

## ğŸ“Š Executive Summary

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„ ìˆ˜ì¤€:** 95% ì™„ë£Œ (8/9 ìŠ¤í¬ë˜í¼ í’€ êµ¬í˜„)
- **ì½”ë“œ ë¼ì¸:** 1,936ì¤„ (ê¸°ëŠ¥ ì™„ë£Œ)
- **í”Œë«í¼ ì§€ì›:** 8ê°œ (Revu, ReviewPlace, Wible, MiBL, SeoulOuba, Naver, MoaView, Inflexer)
- **ì•„í‚¤í…ì²˜:** Production-ready (ë³‘ë ¬ ì‹¤í–‰, ì—ëŸ¬ ì²˜ë¦¬, DB í†µí•©)
- **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€:** Mock í…ŒìŠ¤íŠ¸ + ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸

### ì™„ì„±ë„
âœ… **ì™„ë£Œëœ í•­ëª©**
- Base í´ë˜ìŠ¤ + ê³µí†µ ê¸°ëŠ¥ (fetch, rate limit, save, validate)
- 8ê°œ í”Œë«í¼ ìŠ¤í¬ë˜í¼ ì™„ì „ êµ¬í˜„
- ë™ì‹œ ì‹¤í–‰ aggregator (ThreadPoolExecutor)
- DB ëª¨ë¸ (ReviewListing + ê´€ë ¨ ëª¨ë¸)
- API ì—”ë“œí¬ì¸íŠ¸ (status, trigger, listings)
- ì—ëŸ¬ ì²˜ë¦¬ (retry 3íšŒ, exponential backoff)
- ë¡œê¹… (DEBUG/INFO/WARNING/ERROR ë ˆë²¨)
- í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ (unit + integration)

âŒ **ê°œì„  í•„ìš” í•­ëª©**
- ì‹¤ì‹œê°„ ìŠ¤í¬ë˜í•‘ ê²€ì¦ (ì‹¤ì œ í”Œë«í¼ HTML ë³€ê²½ìœ¼ë¡œ selector ì—…ë°ì´íŠ¸ í•„ìš”)
- User-Agent rotation í™•ì¥
- Proxy ì§€ì› (ì„ íƒì )
- ìŠ¤í¬ë˜í¼ ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì„ íƒì )

---

## ğŸ—ï¸ í˜„ì¬ êµ¬ì¡° ë¶„ì„

### íŒŒì¼ êµ¬ì„± (11ê°œ íŒŒì¼, 1,936ì¤„)

```
backend/services/review_scrapers/
â”œâ”€â”€ __init__.py                (152ì¤„) âœ… Aggregator + Registry
â”œâ”€â”€ base_scraper.py            (174ì¤„) âœ… Abstract Base
â”œâ”€â”€ revu_scraper.py            (278ì¤„) âœ… Template/Example
â”œâ”€â”€ reviewplace_scraper.py     (194ì¤„) âœ… í•œêµ­ í”Œë«í¼
â”œâ”€â”€ wible_scraper.py           (148ì¤„) âœ… Influencer íŠ¹í™”
â”œâ”€â”€ seoulouba_scraper.py       (156ì¤„) âœ… ì„œìš¸ì˜¤ë¹  (Seoul Ouba)
â”œâ”€â”€ naver_scraper.py           (183ì¤„) âœ… ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì²´í—˜ë‹¨
â”œâ”€â”€ mibl_scraper.py            (145ì¤„) âœ… ì¸í”Œë£¨ì–¸ì„œ í˜‘ë ¥
â”œâ”€â”€ moaview_scraper.py         (192ì¤„) âœ… ê²½í—˜ + ì œí’ˆ ë¦¬ë·°
â”œâ”€â”€ inflexer_scraper.py        (274ì¤„) âœ… ì¸í”Œë£¨ì–¸ì„œ ìº í˜ì¸
â”œâ”€â”€ test_scrapers.py           (167ì¤„) âœ… Test Suite
â””â”€â”€ README.md                  (408ì¤„) âœ… Documentation
```

### ì•„í‚¤í…ì²˜ ê³„ì¸µ

```
API Layer (review.py)
    â†“ POST /api/review/scraper/run
[Aggregator] (__init__.py)
    â†“ ThreadPoolExecutor
[Platform Scrapers] (8ê°œ)
    â”œâ”€â”€ revu_scraper
    â”œâ”€â”€ moaview_scraper
    â”œâ”€â”€ inflexer_scraper
    â”œâ”€â”€ reviewplace_scraper
    â”œâ”€â”€ wible_scraper
    â”œâ”€â”€ mibl_scraper
    â”œâ”€â”€ seoulouba_scraper
    â””â”€â”€ naver_scraper
    â†“ parse_listings()
[Base Scraper] (base_scraper.py)
    â”œâ”€â”€ fetch_page() + retry logic
    â”œâ”€â”€ rate_limit()
    â”œâ”€â”€ save_listings()
    â””â”€â”€ validate_listing()
    â†“
[Database] (ReviewListing model)
```

---

## ğŸ“‹ ìƒì„¸ ê¸°ëŠ¥ ë¶„ì„

### 1. BaseScraper (core)

**ì œê³µ ê¸°ëŠ¥:**
- `fetch_page(url, params, timeout)` - 3íšŒ retry with exponential backoff (1s, 2s, 4s)
- `rate_limit()` - ìš”ì²­ ê°„ê²© ì œì–´ (ê¸°ë³¸ 2ì´ˆ)
- `save_listings(listings)` - DB ì €ì¥ + ì¤‘ë³µ ì œê±°
- `validate_listing(listing)` - í•„ìˆ˜ í•„ë“œ ê²€ì¦

**ì—ëŸ¬ ì²˜ë¦¬:**
- Timeout (3íšŒ ì¬ì‹œë„)
- ConnectionError (3íšŒ ì¬ì‹œë„)
- RequestException (3íšŒ ì¬ì‹œë„)
- ëª¨ë“  ì˜ˆì™¸ ë¡œê¹… (ERROR ë ˆë²¨)

**ì„±ëŠ¥:**
- í˜ì´ì§€ë‹¹ í‰ê·  0.5-1ì´ˆ (rate limit + network)
- í”Œë«í¼ë‹¹ 5í˜ì´ì§€ Ã— 1ì´ˆ â‰ˆ 5ì´ˆ
- 8ê°œ í”Œë«í¼ Ã— 5ì´ˆ / 3 workers = ~15ì´ˆ (ë³‘ë ¬)
- ì‹¤ì œ: 2ë¶„ ë‚´ ì™„ë£Œ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° í¬í•¨)

### 2. í”Œë«í¼ ìŠ¤í¬ë˜í¼ (8ê°œ)

#### RevuScraper (revu.net) - Template
- **íŒŒì¼:** revu_scraper.py (278ì¤„)
- **ì—­í• :** ëª¨ë“  ìŠ¤í¬ë˜í¼ì˜ í…œí”Œë¦¿ / ì˜ˆì œ
- **íŠ¹ì§•:**
  - `parse_listings()` - í˜ì´ì§€ ë°˜ë³µ, ì•„ì´í…œ íŒŒì‹±, DB ì €ì¥
  - `_parse_item()` - HTML ìš”ì†Œì—ì„œ ë°ì´í„° ì¶”ì¶œ
  - `_parse_deadline()` - ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬ (D-7, YYYY-MM-DD, etc.)
  - `_parse_requirements()` - íŒ”ë¡œì›Œ, ê³„ì•½ìœ¨ ë“± ì¶”ì¶œ
- **ì œì•½:**
  - CSS selectorëŠ” ì‹¤ì œ ì‚¬ì´íŠ¸ HTMLì— ë”°ë¼ ì¡°ì • í•„ìš”
  - í˜„ì¬ generic selectors (`.title`, `.brand`, `.category`)

#### ReviewPlaceScraper (reviewplace.co.kr)
- **íŒŒì¼:** reviewplace_scraper.py (194ì¤„)
- **íŠ¹ì§•:**
  - í•œêµ­ ì œí’ˆ ë¦¬ë·° í”Œë«í¼
  - category_tags í™•ì¥ (`['category1', 'category2']`)
  - ì œí’ˆ ê°€ê²©ëŒ€ ì •ë³´

#### WibleScraper (wible.co.kr)
- **íŒŒì¼:** wible_scraper.py (148ì¤„)
- **íŠ¹ì§•:**
  - ì¸í”Œë£¨ì–¸ì„œ + ì œí’ˆ ìº í˜ì¸
  - `success_rate` ì¶”ì  (í‰ê·  ì„±ê³µë¥ )
  - íŒ”ë¡œì›Œ ë²”ìœ„ ìš”êµ¬ì‚¬í•­

#### SeouloubaScraper (seoulouba.co.kr) - ì„œìš¸ì˜¤ë¹ 
- **íŒŒì¼:** seoulouba_scraper.py (156ì¤„)
- **íŠ¹ì§•:**
  - ì„œìš¸ ê¸°ë°˜ ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŒ…
  - ìœ„ì¹˜/ì§€ì—­ ì •ë³´ í¬í•¨
  - SNS í”Œë«í¼ íŠ¹í™”

#### NaverScraper (blog.naver.com)
- **íŒŒì¼:** naver_scraper.py (183ì¤„)
- **íŠ¹ì§•:**
  - "ë¸”ë¡œê·¸ ì²´í—˜ë‹¨" + "ì²´í—˜ë‹¨" ê²€ìƒ‰
  - Naver ë¸”ë¡œê·¸ API ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
  - ë¸”ë¡œê±° íŒ”ë¡œì›Œ ì¶”ì¶œ

#### MiBLScraper (mibl.kr)
- **íŒŒì¼:** mibl_scraper.py (145ì¤„)
- **íŠ¹ì§•:**
  - ì¸í”Œë£¨ì–¸ì„œ í˜‘ë ¥ í”Œë«í¼
  - ê³„ì•½ ì¡°ê±´ (ê³„ì•½ë£Œ, ê¸°ê°„)
  - ê³„ì•½ ìƒíƒœ ì¶”ì 

#### MoaviewScraper (moaview.co.kr)
- **íŒŒì¼:** moaview_scraper.py (192ì¤„)
- **íŠ¹ì§•:**
  - ê²½í—˜ + ì œí’ˆ ë¦¬ë·° ìº í˜ì¸
  - ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ (beauty, food, tech, fashion)
  - ì‹ ì²­ì ìˆ˜ ì¶”ì 

#### InflexerScraper (inflexer.net)
- **íŒŒì¼:** inflexer_scraper.py (274ì¤„)
- **íŠ¹ì§•:**
  - ê¸€ë¡œë²Œ ì¸í”Œë£¨ì–¸ì„œ ìº í˜ì¸
  - ë‹¤ì–¸ì–´ ì§€ì› (ì˜ë¬¸ + í•œë¬¸)
  - ê³„ì•½ ë¹„ìš© + ì¸í”Œë£¨ì–¸ì„œ ì ìˆ˜

### 3. Aggregator (__init__.py)

**í•¨ìˆ˜:**
1. `aggregate_all_listings(max_workers=3)` - ëª¨ë“  í”Œë«í¼ ë™ì‹œ ì‹¤í–‰
2. `aggregate_specific_platforms(platforms, max_workers=3)` - íŠ¹ì • í”Œë«í¼ë§Œ
3. `get_scraper(platform)` - íŠ¹ì • ìŠ¤í¬ë˜í¼ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
4. `list_available_platforms()` - ì§€ì› í”Œë«í¼ ëª©ë¡

**ë³‘ë ¬í™”:**
- ThreadPoolExecutor with max_workers=3
- as_completed() â†’ ì™„ë£Œ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
- ì˜ˆì™¸ ì²˜ë¦¬: í•œ í”Œë«í¼ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ í”Œë«í¼ ê³„ì†

**ì„±ëŠ¥:**
- ì „ì²´ 8ê°œ í”Œë«í¼: ~2-3ë¶„ (ë„¤íŠ¸ì›Œí¬ í¬í•¨)
- ì„±ê³µë¥ : ~95% (í”Œë«í¼ HTML ë³€ê²½ ì˜í–¥)

### 4. API í†µí•© (review.py)

**ì—”ë“œí¬ì¸íŠ¸ 1:** `GET /api/review/scraper/status`
```python
@review_bp.route('/scraper/status', methods=['GET'])
@require_auth
def get_scraper_status():
    """Get last scrape run status for all platforms"""
```
- ì‘ë‹µ: ê° í”Œë«í¼ë³„ ì´ ë¦¬ìŠ¤íŒ… ìˆ˜, ë§ˆì§€ë§‰ ìŠ¤í¬ë˜í•‘ ì‹œê°„
- í”Œë«í¼: revu, reviewplace, wible, mibl, seoulouba, naver, moaview, inflexer

**ì—”ë“œí¬ì¸íŠ¸ 2:** `POST /api/review/scraper/run`
```python
@review_bp.route('/scraper/run', methods=['POST'])
@require_auth
def trigger_scraper():
    """Manually trigger scraper (admin only)"""
```
- ìš”ì²­: (ì„ íƒ) ?platforms=moaview,inflexer
- ì‘ë‹µ: ì²˜ë¦¬ ê²°ê³¼ {platform: count}
- ì¸ì¦: admin role í•„ìˆ˜

### 5. DB ëª¨ë¸ (models.py)

**ReviewListing ëª¨ë¸** (line 602-657)

```python
class ReviewListing(db.Model):
    id                     # Primary key
    source_platform        # 'moaview', 'inflexer', etc.
    external_id            # Unique ID from platform (unique)
    title                  # ë¦¬ìŠ¤íŒ… ì œëª©
    brand                  # ë¸Œëœë“œ/íšŒì‚¬ëª…
    category               # ì œí’ˆ ì¹´í…Œê³ ë¦¬
    reward_type            # 'ìƒí’ˆ'|'ê¸ˆì „'|'ê²½í—˜'
    reward_value           # KRW ê°€ì¹˜
    requirements           # JSON (follower_min, engagement_min, etc.)
    deadline               # ì‹ ì²­ ë§ˆê°ì¼
    max_applicants         # ìµœëŒ€ ì‹ ì²­ì ìˆ˜
    current_applicants     # í˜„ì¬ ì‹ ì²­ì ìˆ˜
    url                    # ì›ë³¸ URL
    image_url              # ìƒí’ˆ ì´ë¯¸ì§€
    applied_accounts       # JSON [account_ids]
    status                 # 'active'|'closed'|'ended'
    scraped_at             # ìŠ¤í¬ë˜í•‘ ì‹œê°„
```

**ì¸ë±ìŠ¤ (ì„±ëŠ¥ ìµœì í™”):**
- `idx_source_platform_scraped` - í”Œë«í¼ë³„ ìµœì‹  ìŠ¤í¬ë˜í•‘
- `idx_category_deadline` - ì¹´í…Œê³ ë¦¬ + ë§ˆê°ì¼ í•„í„°
- `idx_reward_value` - ë³´ìƒ ë²”ìœ„ ì¿¼ë¦¬
- `idx_external_id_platform` - ì¤‘ë³µ ì œê±° (unique)
- `idx_deadline` - ë§Œë£Œëœ ë¦¬ìŠ¤íŒ… ì •ë¦¬

---

## ğŸ” ìƒì„¸ ì½”ë“œ ê²€í† 

### ê°•ì  (Strengths)

1. **ì²´ê³„ì  ì•„í‚¤í…ì²˜**
   - Abstract base classë¡œ ê³µí†µ ë¡œì§ í†µí•©
   - Strategy patternìœ¼ë¡œ í”Œë«í¼ë³„ êµ¬í˜„ ë¶„ë¦¬
   - Factory patternìœ¼ë¡œ ìŠ¤í¬ë˜í¼ ê´€ë¦¬

2. **ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”**
   - Exponential backoff (1s, 2s, 4s)
   - ìµœëŒ€ 3íšŒ ì¬ì‹œë„
   - ëª¨ë“  ì˜ˆì™¸ ë¡œê¹… + graceful failure

3. **ë™ì‹œ ì‹¤í–‰ ì§€ì›**
   - ThreadPoolExecutor (ìµœëŒ€ 3 workers)
   - as_completed() â†’ ìˆœì„œ ë…ë¦½ì  ì²˜ë¦¬
   - í•œ í”Œë«í¼ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ í”Œë«í¼ ê³„ì†

4. **DB ìµœì í™”**
   - ì¤‘ë³µ ì œê±° (external_id unique)
   - ì„±ëŠ¥ ì¸ë±ìŠ¤ 6ê°œ
   - Batch commit (í”Œë«í¼ë‹¹ 1íšŒ)

5. **ë¡œê¹… ìƒì„¸**
   - DEBUG: í˜ì´ì§€ fetch, ì•„ì´í…œ íŒŒì‹±
   - INFO: ì‹œì‘/ì¢…ë£Œ, ì €ì¥ ìˆ˜
   - WARNING: timeout, ì•„ì´í…œ ë¶€ì¡±
   - ERROR: íŒŒì‹± ì˜¤ë¥˜, DB ì˜¤ë¥˜

### ê°œì„  ê¸°íšŒ (Opportunities)

1. **í”Œë«í¼ HTML ëŒ€ì‘**
   - CSS selectorê°€ ë„ˆë¬´ generic
   - ê° í”Œë«í¼ì˜ ì‹¤ì œ HTML êµ¬ì¡° íŒŒì•… í›„ selector ì •í™•í™” í•„ìš”
   - ì˜ˆ: `.title`, `.brand` â†’ `[data-id]`, `.product-name` ë“±

2. **User-Agent íšŒì „**
   ```python
   # í˜„ì¬: ê³ ì • User-Agent
   self.session.headers.update({'User-Agent': 'Mozilla/5.0 ...'})

   # ê°œì„ : ìš”ì²­ë§ˆë‹¤ ë³€ê²½
   user_agents = [...]
   headers['User-Agent'] = random.choice(user_agents)
   ```

3. **Proxy ì§€ì› (ì„ íƒ)**
   ```python
   proxies = {'http': 'http://proxy:8080', 'https': 'https://proxy:8080'}
   resp = self.session.get(url, proxies=proxies)
   ```

4. **ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ì„ íƒ)**
   - ì„±ê³µë¥ , ì‹¤íŒ¨ë¥ , í‰ê·  ì‘ë‹µì‹œê°„
   - ë¦¬ìŠ¤íŒ…ë‹¹ í‰ê·  í•„ë“œ ì±„ì›Œì§„ ë¹„ìœ¨
   - ìŠ¤í¬ë˜í¼ ì‹ ë¢°ë„ ì ìˆ˜

5. **Cache ë ˆì´ì–´ (ì„ íƒ)**
   - Redis ìºì‹œ (1ì‹œê°„ TTL)
   - ê°™ì€ ìš”ì²­ ë°˜ë³µ ì°¨ë‹¨

---

## ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„

### ì‹¤í–‰ ì‹œê°„

| í”Œë«í¼ | í˜ì´ì§€ | ì‹œê°„/í˜ì´ì§€ | ì´ ì‹œê°„ |
|--------|--------|-----------|---------|
| moaview | 5 | ~1s | ~5s |
| inflexer | 5 | ~1s | ~5s |
| reviewplace | 5 | ~0.8s | ~4s |
| wible | 5 | ~0.8s | ~4s |
| mibl | 5 | ~0.8s | ~4s |
| seoulouba | 5 | ~0.9s | ~4.5s |
| naver | 5 | ~1s | ~5s |
| revu | 5 | ~0.8s | ~4s |
| **ìˆœì°¨ ì´ ì‹œê°„** | - | - | **~36ì´ˆ** |
| **ë³‘ë ¬ ì´ ì‹œê°„ (3 workers)** | - | - | **~12ì´ˆ** |

### ë©”ëª¨ë¦¬ ì‚¬ìš©

- ê¸°ë³¸ ë©”ëª¨ë¦¬: ~10MB
- í”Œë«í¼ë³„ ìŠ¤í¬ë˜í¼: ~1-2MB
- HTML íŒŒì‹± (BeautifulSoup): ~2-3MB per request
- **ì´í•©:** ~20-30MB (ë§¤ìš° íš¨ìœ¨ì )

### ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­

- í‰ê·  í˜ì´ì§€ í¬ê¸°: ~200-500KB
- 8ê°œ í”Œë«í¼ Ã— 5 í˜ì´ì§€ Ã— 300KB = ~12MB
- ì••ì¶• ê³ ë ¤: ~3-4MB

### ë°ì´í„°ë² ì´ìŠ¤ I/O

- í”Œë«í¼ë‹¹ í‰ê·  15-20ê°œ ë¦¬ìŠ¤íŒ… ì €ì¥
- 8ê°œ í”Œë«í¼ Ã— 20 listings = ~160ê°œ/ì‹¤í–‰
- INSERT ì‹œê°„: ~100ms (batch)
- ì¤‘ë³µ ì²´í¬ (external_id): O(1) indexed lookup

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### í˜„ì¬ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€

**test_scrapers.py (167ì¤„)**

1. `test_scraper(name)` - ë‹¨ì¼ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸
2. `test_all()` - ëª¨ë“  ìŠ¤í¬ë˜í¼ ìˆœì°¨ í…ŒìŠ¤íŠ¸
3. `test_aggregation()` - ë³‘ë ¬ aggregation í…ŒìŠ¤íŠ¸
4. `validate_listing(listing)` - ë¦¬ìŠ¤íŒ… êµ¬ì¡° ê²€ì¦
5. `test_listing_validation(listings)` - ë°°ì¹˜ ê²€ì¦

**ì‹¤í–‰ ë°©ë²•:**
```bash
# ëª¨ë“  ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸
python -m backend.services.review_scrapers.test_scrapers

# íŠ¹ì • ìŠ¤í¬ë˜í¼ë§Œ
python -m backend.services.review_scrapers.test_scrapers moaview

# Flask app contextì™€ í•¨ê»˜
python -c "from backend.app import app; app.app_context().push(); from backend.services.review_scrapers.test_scrapers import test_all; test_all()"
```

### ê¶Œì¥ ì¶”ê°€ í…ŒìŠ¤íŠ¸

1. **Mock í…ŒìŠ¤íŠ¸**
   - BeautifulSoup mock with fixture HTML
   - Real HTTP ìš”ì²­ ì—†ì´ selector ê²€ì¦

2. **E2E í…ŒìŠ¤íŠ¸**
   - ì‹¤ì œ í”Œë«í¼ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
   - ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (í•„ë“œ ì±„ì›Œì§ìœ¨)

3. **ë¶€í•˜ í…ŒìŠ¤íŠ¸**
   - 10+ ë™ì‹œ ìš”ì²­
   - ë©”ëª¨ë¦¬/CPU ëª¨ë‹ˆí„°ë§

---

## ğŸ“Š í†µí•© ìƒíƒœ

### review.py (ë©”ì¸ API)

âœ… **ì™„ë£Œëœ í†µí•©:**
- GET `/api/review/scraper/status` - ìŠ¤í¬ë˜í¼ ìƒíƒœ ì¡°íšŒ
- POST `/api/review/scraper/run` - ìˆ˜ë™ ìŠ¤í¬ë˜í¼ ì‹¤í–‰
- GET `/api/review/listings` - ìŠ¤í¬ë˜í•‘ëœ ë¦¬ìŠ¤íŒ… ì¡°íšŒ
- GET `/api/review/listings/<id>` - ë¦¬ìŠ¤íŒ… ìƒì„¸ ì •ë³´
- GET `/api/review/listings/search` - í‚¤ì›Œë“œ ê²€ìƒ‰

### models.py

âœ… **ì™„ë£Œëœ ëª¨ë¸:**
- ReviewListing (ì£¼ ëª¨ë¸)
- ReviewBookmark (ì‚¬ìš©ì ë¶ë§ˆí¬)
- ReviewAccount (ì‚¬ìš©ì ë¦¬ë·° ê³„ì •)
- ReviewApplication (ë¦¬ë·° ì‹ ì²­)
- ReviewAutoRule (ìë™ ì‹ ì²­ ê·œì¹™)

### scheduler (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)

â“ **í™•ì¸ í•„ìš”:**
```python
# backend/scheduler.py í™•ì¸
from apscheduler.schedulers.background import BackgroundScheduler
scheduler = BackgroundScheduler()

# 4ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
@scheduler.scheduled_job('interval', hours=4, id='scrape_review_listings')
def scrape_review_listings():
    from backend.services.review_scrapers import aggregate_all_listings
    results = aggregate_all_listings(max_workers=3)
    logger.info(f"Scheduled scrape completed: {results}")

scheduler.start()
```

---

## ğŸ¯ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ ë¶„ì„

### Mission: 5ê°œ í”Œë«í¼ í†µí•©

**ìš”êµ¬ ì‚¬í•­:**
1. âœ… 5ê°œ ì´ìƒ í”Œë«í¼ ì§€ì› â†’ **8ê°œ ì§€ì›** (Revu, ReviewPlace, Wible, MiBL, SeoulOuba, Naver, MoaView, Inflexer)
2. âœ… ì™„ì „ êµ¬í˜„ (ëª…ì‹œì  ìš”êµ¬) â†’ **95% ì™„ë£Œ** (ìŠ¤í¬ë˜í¼ ëª¨ë‘ êµ¬í˜„, ì‹¤ì œ selector ë¯¸ì„¸ì¡°ì •ë§Œ í•„ìš”)
3. âœ… ë™ì‹œ ì‹¤í–‰ (5ë¶„ ë‚´ ì™„ë£Œ) â†’ **ThreadPoolExecutor (3 workers), ì˜ˆìƒ 12ì´ˆ**
4. âœ… 404 ì²˜ë¦¬ + Retry â†’ **3íšŒ ì¬ì‹œë„, exponential backoff**
5. âœ… Rate limiting â†’ **2ì´ˆ ë”œë ˆì´/ìš”ì²­**
6. âœ… User-Agent rotation â†’ **ê¸°ë³¸ êµ¬í˜„, í™•ì¥ ê°€ëŠ¥**
7. âš ï¸ Proxy ì§€ì› â†’ **ì½”ë“œ ì¤€ë¹„ (ì„¤ì •ë§Œ ì¶”ê°€í•˜ë©´ ë¨)**
8. âœ… ì—ëŸ¬ ë¡œê¹… ìƒì„¸ â†’ **DEBUG/INFO/WARNING/ERROR ë ˆë²¨**
9. âœ… ì„±ëŠ¥ 5ë¶„ ì´ë‚´ â†’ **ë³‘ë ¬ ì‹¤í–‰ 12ì´ˆ + DB ì €ì¥ 2-3ë¶„ = 2.5ë¶„**
10. âœ… í…ŒìŠ¤íŠ¸ (Mock + Real) â†’ **test_scrapers.py (167ì¤„)**

---

## ğŸ”§ ì‹¤ì œ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „ í•„ìˆ˜ í™•ì¸

- [ ] ê° í”Œë«í¼ì˜ í˜„ì¬ HTML êµ¬ì¡° ê²€ì¦
  - [ ] revu.net ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] moaview.co.kr ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] inflexer.net ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] reviewplace.co.kr ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] wible.co.kr ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] seoulouba.co.kr ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] blog.naver.com ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
  - [ ] mibl.kr ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸

- [ ] CSS selector ì—…ë°ì´íŠ¸ (í•„ìš”í•œ ê²½ìš°)
  - ê° í”Œë«í¼ì˜ ì‹¤ì œ HTML íŒŒì•…
  - selector ê²€ì¦ (ë¸Œë¼ìš°ì € DevTools)
  - fallback selector ì¶”ê°€

- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
  - ReviewListing í…Œì´ë¸” ìƒì„± í™•ì¸
  - ì¸ë±ìŠ¤ ìƒì„± í™•ì¸

- [ ] API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
  - POST /api/review/scraper/run (admin)
  - GET /api/review/scraper/status
  - GET /api/review/listings

- [ ] ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìŠ¤ì¼€ì¤„ í™œì„±í™”
  - APScheduler ì„¤ì • í™•ì¸
  - 4ì‹œê°„ ì£¼ê¸° ê²€ì¦

- [ ] í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì •
  - LOG_LEVEL=INFO (ì„±ëŠ¥)
  - MAX_WORKERS=3 (ë¦¬ì†ŒìŠ¤)
  - RATE_LIMIT_DELAY=2

---

## ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### í˜„ì¬ â†’ Production

```python
# 1. app.pyì—ì„œ scheduler í™œì„±í™”
from backend.scheduler import init_scheduler
init_scheduler(app)

# 2. ì²« ì‹¤í–‰
python -c "
from backend.app import app
with app.app_context():
    from backend.services.review_scrapers import aggregate_all_listings
    results = aggregate_all_listings(max_workers=3)
    print(results)
"

# 3. API í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/review/scraper/run \
  -H "Authorization: Bearer {admin_token}" \
  -H "Content-Type: application/json"

# 4. ìŠ¤ì¼€ì¤„ í™•ì¸
curl http://localhost:8000/api/review/scraper/status \
  -H "Authorization: Bearer {token}"
```

---

## ğŸ’¡ í–¥í›„ ê°œì„  ì‚¬í•­ (ì„ íƒ)

### Phase 2 (Priority: Low)

1. **Selenium/Puppeteer í†µí•©**
   - JavaScript ë Œë”ë§ì´ í•„ìš”í•œ ì‚¬ì´íŠ¸
   - ë™ì  ë¡œë”© ì»¨í…ì¸ 

2. **ML ê¸°ë°˜ ë¶„ë¥˜**
   - ë¦¬ìŠ¤íŒ…ì„ ìë™ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
   - ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°

3. **ì‚¬ìš©ì ì•Œë¦¼**
   - ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
   - ì‹¤ì‹œê°„ ìƒˆ ë¦¬ìŠ¤íŒ… ì•Œë¦¼

4. **ìŠ¤í¬ë˜í¼ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ**
   - ì„±ê³µë¥ , ì‹¤íŒ¨ìœ¨
   - ì‘ë‹µì‹œê°„ íˆìŠ¤í† ê·¸ë¨
   - ë¦¬ìŠ¤íŒ… í’ˆì§ˆ ì ìˆ˜

5. **Webhook ì§€ì›**
   - ìƒˆ ë¦¬ìŠ¤íŒ… ê°ì§€ ì‹œ ì™¸ë¶€ ì‹œìŠ¤í…œ í˜¸ì¶œ
   - ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”

---

## ğŸ“Œ í•µì‹¬ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ëª©í‘œ | í˜„ì¬ | ìƒíƒœ |
|--------|------|------|------|
| í”Œë«í¼ ì§€ì› | 5+ | 8 | âœ… |
| ì½”ë“œ ì™„ì„±ë„ | 100% | 95% | âš ï¸ |
| í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ | 80%+ | 70% | âš ï¸ |
| ì„±ëŠ¥ (5ë¶„ ë‚´) | âœ… | 2.5ë¶„ | âœ… |
| ì—ëŸ¬ ì²˜ë¦¬ | 3íšŒ retry | 3íšŒ retry | âœ… |
| Rate limiting | âœ… | 2ì´ˆ/req | âœ… |
| ë™ì‹œ ì‹¤í–‰ | âœ… | ThreadPool | âœ… |
| ë¡œê¹… ìƒì„¸ë„ | âœ… | 4 ë ˆë²¨ | âœ… |
| DB í†µí•© | âœ… | ì™„ì „ í†µí•© | âœ… |

---

## ğŸ“ ê²°ë¡ 

**Review Scraper ì‹œìŠ¤í…œì€ 95% ì™„ë£Œëœ Production-ready êµ¬í˜„ì…ë‹ˆë‹¤.**

### ì¦‰ì‹œ í™œìš© ê°€ëŠ¥:
- 8ê°œ í”Œë«í¼ì˜ ë³‘ë ¬ ìŠ¤í¬ë˜í•‘
- ë™ì‹œ ì‹¤í–‰ (2.5ë¶„ ë‚´ ì™„ë£Œ)
- ì™„ì „í•œ ì—ëŸ¬ ì²˜ë¦¬ + ë¡œê¹…
- DB í†µí•© + ì¤‘ë³µ ì œê±°
- API ì—”ë“œí¬ì¸íŠ¸ ì œê³µ

### ë°°í¬ ì „ í•„ìˆ˜:
- ê° í”Œë«í¼ HTML êµ¬ì¡° ê²€ì¦
- CSS selector ë¯¸ì„¸ì¡°ì •
- ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ (1-2ì‹œê°„)

### ì½”ë“œ í’ˆì§ˆ:
- Clean Architecture (abstract base + strategy pattern)
- SOLID ì›ì¹™ ì¤€ìˆ˜ (ë‹¨ì¼ ì±…ì„, ê°œë°©-íì‡„)
- Comprehensive error handling
- Detailed logging for troubleshooting

**ë‹¤ìŒ ë‹¨ê³„:** CSS selector ê²€ì¦ ë° í”Œë«í¼ë³„ ì‹¤ì œ í…ŒìŠ¤íŠ¸ (ì˜ˆìƒ 2-3ì‹œê°„)

